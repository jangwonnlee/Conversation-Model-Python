{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, json, copy, os\n",
    "import cPickle as pickle\n",
    "from easydict import EasyDict as edict\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "args = edict(\n",
    "    {      \n",
    "        'agt': 9,\n",
    "        'usr': 1,\n",
    "        'max_turn': 40,\n",
    "        'movie_kb_path': './movie_kb.1k.p',\n",
    "        'dqn_hidden_size': 80,\n",
    "        'experience_replay_pool_size': 1000,\n",
    "        'episodes': 500,\n",
    "        'simulation_epoch_size': 100,\n",
    "        'write_model_dir': './',\n",
    "        'run_mode': 3,\n",
    "        'auto_suggest': 0,\n",
    "        'act_level': 1,\n",
    "        'slot_err_prob': 0.00,\n",
    "        'intent_err_prob': 0.00,\n",
    "        'batch_size': 16,\n",
    "        'goal_file_path': './user_goals_first_turn_template.part.movie.v1.p',\n",
    "        'warm_start': 1,\n",
    "        'warm_start_epochs': 120,\n",
    "        'dict_path': './dicts.v3.p',\n",
    "        'act_set': './dia_acts.txt',\n",
    "        'slot_set': './slot_set.txt',\n",
    "        'epsilon': 0,\n",
    "        'gamma': 0.9,\n",
    "        'predict_mode': False,\n",
    "        'trained_model_path': None,\n",
    "        'cmd_input_mode': 0,\n",
    "        'slot_err_mode': 0,\n",
    "        'learning_phase': 'all',\n",
    "        'nlg_model_path': './lstm_tanh_relu_[1468202263.38]_2_0.610.p',\n",
    "        'diaact_nl_pairs': './dia_act_nl_pairs.v6.json',\n",
    "        'nlu_model_path': './lstm_[1468447442.91]_39_80_0.921.p',\n",
    "        'success_rate_threshold': 0.3,\n",
    "        'save_check_point': 10\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = vars(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialog Parameters: \n",
      "{\n",
      "  \"simulation_epoch_size\": 100, \n",
      "  \"slot_err_mode\": 0, \n",
      "  \"diaact_nl_pairs\": \"./dia_act_nl_pairs.v6.json\", \n",
      "  \"save_check_point\": 10, \n",
      "  \"episodes\": 500, \n",
      "  \"predict_mode\": false, \n",
      "  \"cmd_input_mode\": 0, \n",
      "  \"goal_file_path\": \"./user_goals_first_turn_template.part.movie.v1.p\", \n",
      "  \"max_turn\": 40, \n",
      "  \"experience_replay_pool_size\": 1000, \n",
      "  \"write_model_dir\": \"./\", \n",
      "  \"usr\": 1, \n",
      "  \"auto_suggest\": 0, \n",
      "  \"run_mode\": 3, \n",
      "  \"trained_model_path\": null, \n",
      "  \"success_rate_threshold\": 0.3, \n",
      "  \"nlu_model_path\": \"./lstm_[1468447442.91]_39_80_0.921.p\", \n",
      "  \"epsilon\": 0, \n",
      "  \"batch_size\": 16, \n",
      "  \"learning_phase\": \"all\", \n",
      "  \"nlg_model_path\": \"./lstm_tanh_relu_[1468202263.38]_2_0.610.p\", \n",
      "  \"act_set\": \"./dia_acts.txt\", \n",
      "  \"movie_kb_path\": \"./movie_kb.1k.p\", \n",
      "  \"slot_err_prob\": 0.0, \n",
      "  \"warm_start\": 1, \n",
      "  \"warm_start_epochs\": 120, \n",
      "  \"dict_path\": \"./dicts.v3.p\", \n",
      "  \"intent_err_prob\": 0.0, \n",
      "  \"slot_set\": \"./slot_set.txt\", \n",
      "  \"act_level\": 1, \n",
      "  \"dqn_hidden_size\": 80, \n",
      "  \"agt\": 9, \n",
      "  \"gamma\": 0.9\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('Dialog Parameters: ')\n",
    "print(json.dumps(params, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_turn = params['max_turn']\n",
    "num_episodes = params['episodes']\n",
    "\n",
    "agt = params['agt']\n",
    "usr = params['usr']\n",
    "\n",
    "dict_path = params['dict_path']\n",
    "goal_file_path = params['goal_file_path']\n",
    "\n",
    "# load the user goals from .p file\n",
    "all_goal_set = pickle.load(open(goal_file_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split goal set\n",
    "split_fold = params.get('split_fold', 5)\n",
    "goal_set = {'train':[], 'valid':[], 'test':[], 'all':[]}\n",
    "for u_goal_id, u_goal in enumerate(all_goal_set):\n",
    "    if u_goal_id % split_fold == 1: goal_set['test'].append(u_goal)\n",
    "    else: goal_set['train'].append(u_goal)\n",
    "    goal_set['all'].append(u_goal)\n",
    "# end split goal set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_kb_path = params['movie_kb_path']\n",
    "movie_kb = pickle.load(open(movie_kb_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_dict(path):\n",
    "    \"\"\" Read in a text file as a dictionary where keys are text and values are indices (line numbers) \"\"\"\n",
    "    \n",
    "    slot_set = {}\n",
    "    with open(path, 'r') as f:\n",
    "        index = 0\n",
    "        for line in f.readlines():\n",
    "            slot_set[line.strip('\\n').strip('\\r')] = index\n",
    "            index += 1\n",
    "    return slot_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_set = text_to_dict(params['act_set'])\n",
    "slot_set = text_to_dict(params['slot_set'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dictionary = pickle.load(open(dict_path, 'rb'))\n",
    "\n",
    "run_mode = params['run_mode']\n",
    "auto_suggest = params['auto_suggest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_params = {}\n",
    "agent_params['max_turn'] = max_turn\n",
    "agent_params['epsilon'] = params['epsilon']\n",
    "agent_params['agent_run_mode'] = params['run_mode']\n",
    "agent_params['agent_act_level'] = params['act_level']\n",
    "\n",
    "agent_params['experience_replay_pool_size'] = params['experience_replay_pool_size']\n",
    "agent_params['dqn_hidden_size'] = params['dqn_hidden_size']\n",
    "agent_params['batch_size'] = params['batch_size']\n",
    "agent_params['gamma'] = params['gamma']\n",
    "agent_params['predict_mode'] = params['predict_mode']\n",
    "agent_params['trained_model_path'] = params['trained_model_path']\n",
    "agent_params['warm_start'] = params['warm_start']\n",
    "agent_params['cmd_input_mode'] = params['cmd_input_mode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\" Prototype for all agent classes, defining the interface they must uphold \"\"\"\n",
    "\n",
    "    def __init__(self, movie_dict=None, act_set=None, slot_set=None, params=None):\n",
    "        \"\"\" Constructor for the Agent class\n",
    "        Arguments:\n",
    "        movie_dict      --  This is here now but doesn't belong - the agent doesn't know about movies\n",
    "        act_set         --  The set of acts. #### Shouldn't this be more abstract? Don't we want our agent to be more broadly usable?\n",
    "        slot_set        --  The set of available slots\n",
    "        \"\"\"\n",
    "        self.movie_dict = movie_dict\n",
    "        self.act_set = act_set\n",
    "        self.slot_set = slot_set\n",
    "        self.act_cardinality = len(act_set.keys())\n",
    "        self.slot_cardinality = len(slot_set.keys())\n",
    "        \n",
    "        self.epsilon = params['epsilon']\n",
    "        self.agent_run_mode = params['agent_run_mode']\n",
    "        self.agent_act_level = params['agent_act_level']\n",
    "        \n",
    "\n",
    "    def initialize_episode(self):\n",
    "        \"\"\" Initialize a new episode. This function is called every time a new episode is run. \"\"\"\n",
    "        self.current_action = {}                    #   TODO Changed this variable's name to current_action\n",
    "        self.current_action['diaact'] = None        #   TODO Does it make sense to call it a state if it has an act? Which act? The Most recent?\n",
    "        self.current_action['inform_slots'] = {}\n",
    "        self.current_action['request_slots'] = {}\n",
    "        self.current_action['turn'] = 0\n",
    "\n",
    "    def state_to_action(self, state, available_actions):\n",
    "        \"\"\" Take the current state and return an action according to the current exploration/exploitation policy\n",
    "        We define the agents flexibly so that they can either operate on act_slot representations or act_slot_value representations.\n",
    "        We also define the responses flexibly, returning a dictionary with keys [act_slot_response, act_slot_value_response]. This way the command-line agent can continue to operate with values\n",
    "        Arguments:\n",
    "        state      --   A tuple of (history, kb_results) where history is a sequence of previous actions and kb_results contains information on the number of results matching the current constraints.\n",
    "        user_action         --   A legacy representation used to run the command line agent. We should remove this ASAP but not just yet\n",
    "        available_actions   --   A list of the allowable actions in the current state\n",
    "        Returns:\n",
    "        act_slot_action         --   An action consisting of one act and >= 0 slots as well as which slots are informed vs requested.\n",
    "        act_slot_value_action   --   An action consisting of acts slots and values in the legacy format. This can be used in the future for training agents that take value into account and interact directly with the database\n",
    "        \"\"\"\n",
    "        act_slot_response = None\n",
    "        act_slot_value_response = None\n",
    "        return {\"act_slot_response\": act_slot_response, \"act_slot_value_response\": act_slot_value_response}\n",
    "\n",
    "\n",
    "    def register_experience_replay_tuple(self, s_t, a_t, reward, s_tplus1, episode_over):\n",
    "        \"\"\"  Register feedback from the environment, to be stored as future training data\n",
    "        Arguments:\n",
    "        s_t                 --  The state in which the last action was taken\n",
    "        a_t                 --  The previous agent action\n",
    "        reward              --  The reward received immediately following the action\n",
    "        s_tplus1            --  The state transition following the latest action\n",
    "        episode_over        --  A boolean value representing whether the this is the final action.\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def set_nlg_model(self, nlg_model):\n",
    "        self.nlg_model = nlg_model  \n",
    "    \n",
    "    def set_nlu_model(self, nlu_model):\n",
    "        self.nlu_model = nlu_model\n",
    "     \n",
    "       \n",
    "    def add_nl_to_action(self, agent_action):\n",
    "        \"\"\" Add NL to Agent Dia_Act \"\"\"\n",
    "        \n",
    "        if agent_action['act_slot_response']:\n",
    "            agent_action['act_slot_response']['nl'] = \"\"\n",
    "            user_nlg_sentence = self.nlg_model.convert_diaact_to_nl(agent_action['act_slot_response'], 'agt') #self.nlg_model.translate_diaact(agent_action['act_slot_response']) # NLG\n",
    "            agent_action['act_slot_response']['nl'] = user_nlg_sentence\n",
    "        elif agent_action['act_slot_value_response']:\n",
    "            agent_action['act_slot_value_response']['nl'] = \"\"\n",
    "            user_nlg_sentence = self.nlg_model.convert_diaact_to_nl(agent_action['act_slot_value_response'], 'agt') #self.nlg_model.translate_diaact(agent_action['act_slot_value_response']) # NLG\n",
    "            agent_action['act_slot_response']['nl'] = user_nlg_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_request_slots = ['moviename', 'theater', 'starttime', 'date', 'numberofpeople', 'genre', 'state', 'city', 'zip', 'critic_rating', 'mpaa_rating', 'distanceconstraints', 'video_format', 'theater_chain', 'price', 'actor', 'description', 'other', 'numberofkids']\n",
    "sys_inform_slots = ['moviename', 'theater', 'starttime', 'date', 'genre', 'state', 'city', 'zip', 'critic_rating', 'mpaa_rating', 'distanceconstraints', 'video_format', 'theater_chain', 'price', 'actor', 'description', 'other', 'numberofkids', 'taskcomplete', 'ticket']\n",
    "\n",
    "feasible_actions = [\n",
    "    ############################################################################\n",
    "    #   greeting actions\n",
    "    ############################################################################\n",
    "    #{'diaact':\"greeting\", 'inform_slots':{}, 'request_slots':{}},\n",
    "    ############################################################################\n",
    "    #   confirm_question actions\n",
    "    ############################################################################\n",
    "    {'diaact':\"confirm_question\", 'inform_slots':{}, 'request_slots':{}},\n",
    "    ############################################################################\n",
    "    #   confirm_answer actions\n",
    "    ############################################################################\n",
    "    {'diaact':\"confirm_answer\", 'inform_slots':{}, 'request_slots':{}},\n",
    "    ############################################################################\n",
    "    #   thanks actions\n",
    "    ############################################################################\n",
    "    {'diaact':\"thanks\", 'inform_slots':{}, 'request_slots':{}},\n",
    "    ############################################################################\n",
    "    #   deny actions\n",
    "    ############################################################################\n",
    "    {'diaact':\"deny\", 'inform_slots':{}, 'request_slots':{}},\n",
    "]\n",
    "\n",
    "############################################################################\n",
    "#   Adding the inform actions\n",
    "############################################################################\n",
    "for slot in sys_inform_slots:\n",
    "    feasible_actions.append({'diaact':'inform', 'inform_slots':{slot:\"PLACEHOLDER\"}, 'request_slots':{}})\n",
    "\n",
    "############################################################################\n",
    "#   Adding the request actions\n",
    "############################################################################\n",
    "for slot in sys_request_slots:\n",
    "    feasible_actions.append({'diaact':'request', 'inform_slots':{}, 'request_slots': {slot: \"UNK\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def initWeight(n,d):\n",
    "    scale_factor = math.sqrt(float(6)/(n + d))\n",
    "    #scale_factor = 0.1\n",
    "    return (np.random.rand(n,d)*2-1)*scale_factor\n",
    "\n",
    "def initWeights(n,d):\n",
    "    \"\"\" Initialization Strategy \"\"\"\n",
    "    #scale_factor = 0.1\n",
    "    scale_factor = math.sqrt(float(6)/(n + d))\n",
    "    return (np.random.rand(n,d)*2-1)*scale_factor\n",
    "\n",
    "nlg_beam_size = 10\n",
    "NO_OUTCOME_YET = 0\n",
    "CONSTRAINT_CHECK_FAILURE = 0\n",
    "NO_VALUE_MATCH = \"NO VALUE MATCHES!!!\"\n",
    "I_DO_NOT_CARE = \"I do not care\"\n",
    "TICKET_AVAILABLE = 'Ticket Available'\n",
    "\n",
    "FAILED_DIALOG = -1\n",
    "SUCCESS_DIALOG = 1\n",
    "\n",
    "CONSTRAINT_CHECK_FAILURE = 0\n",
    "CONSTRAINT_CHECK_SUCCESS = 1\n",
    "\n",
    "start_dia_acts = {\n",
    "    #'greeting':[],\n",
    "    'request':['moviename', 'starttime', 'theater', 'city', 'state', 'date', 'genre', 'ticket', 'numberofpeople']\n",
    "}\n",
    "\n",
    "def mergeDicts(d0, d1):\n",
    "    for k in d1:\n",
    "        if k in d0:\n",
    "            d0[k] += d1[k]\n",
    "        else:\n",
    "            d0[k] = d1[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.model = {}\n",
    "        # input-hidden\n",
    "        self.model['Wxh'] = initWeight(input_size, hidden_size)\n",
    "        self.model['bxh'] = np.zeros((1, hidden_size))\n",
    "      \n",
    "        # hidden-output\n",
    "        self.model['Wd'] = initWeight(hidden_size, output_size)*0.1\n",
    "        self.model['bd'] = np.zeros((1, output_size))\n",
    "\n",
    "        self.update = ['Wxh', 'bxh', 'Wd', 'bd']\n",
    "        self.regularize = ['Wxh', 'Wd']\n",
    "\n",
    "        self.step_cache = {}\n",
    "        \n",
    "\n",
    "    def getStruct(self):\n",
    "        return {'model': self.model, 'update': self.update, 'regularize': self.regularize}\n",
    "    \n",
    "    \n",
    "    \"\"\"Activation Function: Sigmoid, or tanh, or ReLu\"\"\"\n",
    "    def fwdPass(self, Xs, params, **kwargs):\n",
    "        predict_mode = kwargs.get('predict_mode', False)\n",
    "        active_func = params.get('activation_func', 'relu')\n",
    " \n",
    "        # input layer to hidden layer\n",
    "        Wxh = self.model['Wxh']\n",
    "        bxh = self.model['bxh']\n",
    "        Xsh = Xs.dot(Wxh) + bxh\n",
    "        \n",
    "        hidden_size = self.model['Wd'].shape[0] # size of hidden layer\n",
    "        H = np.zeros((1, hidden_size)) # hidden layer representation\n",
    "        \n",
    "        if active_func == 'sigmoid':\n",
    "            H = 1/(1+np.exp(-Xsh))\n",
    "        elif active_func == 'tanh':\n",
    "            H = np.tanh(Xsh)\n",
    "        elif active_func == 'relu': # ReLU \n",
    "            H = np.maximum(Xsh, 0)\n",
    "        else: # no activation function\n",
    "            H = Xsh\n",
    "                \n",
    "        # decoder at the end; hidden layer to output layer\n",
    "        Wd = self.model['Wd']\n",
    "        bd = self.model['bd']\n",
    "        Y = H.dot(Wd) + bd\n",
    "        \n",
    "        # cache the values in forward pass, we expect to do a backward pass\n",
    "        cache = {}\n",
    "        if not predict_mode:\n",
    "            cache['Wxh'] = Wxh\n",
    "            cache['Wd'] = Wd\n",
    "            cache['Xs'] = Xs\n",
    "            cache['Xsh'] = Xsh\n",
    "            cache['H'] = H\n",
    "            \n",
    "            cache['bxh'] = bxh\n",
    "            cache['bd'] = bd\n",
    "            cache['activation_func'] = active_func\n",
    "            \n",
    "            cache['Y'] = Y\n",
    "            \n",
    "        return Y, cache\n",
    "    \n",
    "    def bwdPass(self, dY, cache):\n",
    "        Wd = cache['Wd']\n",
    "        H = cache['H']\n",
    "        Xs = cache['Xs']\n",
    "        Xsh = cache['Xsh']\n",
    "        Wxh = cache['Wxh']\n",
    " \n",
    "        active_func = cache['activation_func']\n",
    "        n,d = H.shape\n",
    "        \n",
    "        dH = dY.dot(Wd.transpose())\n",
    "        # backprop the decoder\n",
    "        dWd = H.transpose().dot(dY)\n",
    "        dbd = np.sum(dY, axis=0, keepdims=True)\n",
    "        \n",
    "        dXsh = np.zeros(Xsh.shape)\n",
    "        dXs = np.zeros(Xs.shape)\n",
    "        \n",
    "        if active_func == 'sigmoid':\n",
    "            dH = (H-H**2)*dH\n",
    "        elif active_func == 'tanh':\n",
    "            dH = (1-H**2)*dH\n",
    "        elif active_func == 'relu':\n",
    "            dH = (H>0)*dH # backprop ReLU\n",
    "        else:\n",
    "            dH = dH\n",
    "              \n",
    "        # backprop to the input-hidden connection\n",
    "        dWxh = Xs.transpose().dot(dH)\n",
    "        dbxh = np.sum(dH, axis=0, keepdims = True)\n",
    "        \n",
    "        # backprop to the input\n",
    "        dXsh = dH\n",
    "        dXs = dXsh.dot(Wxh.transpose())\n",
    "        \n",
    "        return {'Wd': dWd, 'bd': dbd, 'Wxh':dWxh, 'bxh':dbxh}\n",
    "    \n",
    "    \n",
    "    \"\"\"batch Forward & Backward Pass\"\"\"\n",
    "    def batchForward(self, batch, params, predict_mode = False):\n",
    "        caches = []\n",
    "        Ys = []\n",
    "        for i,x in enumerate(batch):\n",
    "            Xs = np.array([x['cur_states']], dtype=float)\n",
    "            \n",
    "            Y, out_cache = self.fwdPass(Xs, params, predict_mode = predict_mode)\n",
    "            caches.append(out_cache)\n",
    "            Ys.append(Y)\n",
    "           \n",
    "        # back up information for efficient backprop\n",
    "        cache = {}\n",
    "        if not predict_mode:\n",
    "            cache['caches'] = caches\n",
    "\n",
    "        return Ys, cache\n",
    "    \n",
    "    def batchDoubleForward(self, batch, params, clone_dqn, predict_mode = False):\n",
    "        caches = []\n",
    "        Ys = []\n",
    "        tYs = []\n",
    "        \n",
    "        for i,x in enumerate(batch):\n",
    "            Xs = x[0]\n",
    "            Y, out_cache = self.fwdPass(Xs, params, predict_mode = predict_mode)\n",
    "            caches.append(out_cache)\n",
    "            Ys.append(Y)\n",
    "            \n",
    "            tXs = x[3]\n",
    "            tY, t_cache = clone_dqn.fwdPass(tXs, params, predict_mode = False)\n",
    "                \n",
    "            tYs.append(tY)\n",
    "            \n",
    "        # back up information for efficient backprop\n",
    "        cache = {}\n",
    "        if not predict_mode:\n",
    "            cache['caches'] = caches\n",
    "\n",
    "        return Ys, cache, tYs\n",
    "    \n",
    "    def batchBackward(self, dY, cache):\n",
    "        caches = cache['caches']\n",
    "        \n",
    "        grads = {}\n",
    "        for i in xrange(len(caches)):\n",
    "            single_cache = caches[i]\n",
    "            local_grads = self.bwdPass(dY[i], single_cache)\n",
    "            mergeDicts(grads, local_grads) # add up the gradients wrt model parameters\n",
    "            \n",
    "        return grads\n",
    "\n",
    "\n",
    "    \"\"\" cost function, returns cost and gradients for model \"\"\"\n",
    "    def costFunc(self, batch, params, clone_dqn):\n",
    "        regc = params.get('reg_cost', 1e-3)\n",
    "        gamma = params.get('gamma', 0.9)\n",
    "        \n",
    "        # batch forward\n",
    "        Ys, caches, tYs = self.batchDoubleForward(batch, params, clone_dqn, predict_mode = False)\n",
    "        \n",
    "        loss_cost = 0.0\n",
    "        dYs = []\n",
    "        for i,x in enumerate(batch):\n",
    "            Y = Ys[i]\n",
    "            nY = tYs[i]\n",
    "            \n",
    "            action = np.array(x[1], dtype=int)\n",
    "            reward = np.array(x[2], dtype=float)\n",
    "            \n",
    "            n_action = np.nanargmax(nY[0])\n",
    "            max_next_y = nY[0][n_action]\n",
    "            \n",
    "            eposide_terminate = x[4]\n",
    "            \n",
    "            target_y = reward\n",
    "            if eposide_terminate != True: target_y += gamma*max_next_y\n",
    "            \n",
    "            pred_y = Y[0][action]\n",
    "            \n",
    "            nY = np.zeros(nY.shape)\n",
    "            nY[0][action] = target_y\n",
    "            Y = np.zeros(Y.shape)\n",
    "            Y[0][action] = pred_y\n",
    "            \n",
    "            # Cost Function\n",
    "            loss_cost += (target_y - pred_y)**2\n",
    "                \n",
    "            dY = -(nY - Y)\n",
    "            #dY = np.minimum(dY, 1)\n",
    "            #dY = np.maximum(dY, -1)\n",
    "            dYs.append(dY)\n",
    "        \n",
    "        # backprop the RNN\n",
    "        grads = self.batchBackward(dYs, caches)\n",
    "        \n",
    "        # add L2 regularization cost and gradients\n",
    "        reg_cost = 0.0\n",
    "        if regc > 0:    \n",
    "            for p in self.regularize:\n",
    "                mat = self.model[p]\n",
    "                reg_cost += 0.5*regc*np.sum(mat*mat)\n",
    "                grads[p] += regc*mat\n",
    "\n",
    "        # normalize the cost and gradient by the batch size\n",
    "        batch_size = len(batch)\n",
    "        reg_cost /= batch_size\n",
    "        loss_cost /= batch_size\n",
    "        for k in grads: grads[k] /= batch_size\n",
    "\n",
    "        out = {}\n",
    "        out['cost'] = {'reg_cost' : reg_cost, 'loss_cost' : loss_cost, 'total_cost' : loss_cost + reg_cost}\n",
    "        out['grads'] = grads\n",
    "        return out\n",
    "\n",
    "\n",
    "    \"\"\" A single batch \"\"\"\n",
    "    def singleBatch(self, batch, params, clone_dqn):\n",
    "        learning_rate = params.get('learning_rate', 0.001)\n",
    "        decay_rate = params.get('decay_rate', 0.999)\n",
    "        momentum = params.get('momentum', 0.1)\n",
    "        grad_clip = params.get('grad_clip', -1e-3)\n",
    "        smooth_eps = params.get('smooth_eps', 1e-8)\n",
    "        sdg_type = params.get('sdgtype', 'rmsprop')\n",
    "        activation_func = params.get('activation_func', 'relu')\n",
    "        \n",
    "        for u in self.update:\n",
    "            if not u in self.step_cache: \n",
    "                self.step_cache[u] = np.zeros(self.model[u].shape)\n",
    "        \n",
    "        cg = self.costFunc(batch, params, clone_dqn)\n",
    "        \n",
    "        cost = cg['cost']\n",
    "        grads = cg['grads']\n",
    "        \n",
    "        # clip gradients if needed\n",
    "        if activation_func.lower() == 'relu':\n",
    "            if grad_clip > 0:\n",
    "                for p in self.update:\n",
    "                    if p in grads:\n",
    "                        grads[p] = np.minimum(grads[p], grad_clip)\n",
    "                        grads[p] = np.maximum(grads[p], -grad_clip)\n",
    "        \n",
    "        # perform parameter update\n",
    "        for p in self.update:\n",
    "            if p in grads:\n",
    "                if sdg_type == 'vanilla':\n",
    "                    if momentum > 0:\n",
    "                        dx = momentum*self.step_cache[p] - learning_rate*grads[p]\n",
    "                    else:\n",
    "                        dx = -learning_rate*grads[p]\n",
    "                    self.step_cache[p] = dx\n",
    "                elif sdg_type == 'rmsprop':\n",
    "                    self.step_cache[p] = self.step_cache[p]*decay_rate + (1.0-decay_rate)*grads[p]**2\n",
    "                    dx = -(learning_rate*grads[p])/np.sqrt(self.step_cache[p] + smooth_eps)\n",
    "                elif sdg_type == 'adgrad':\n",
    "                    self.step_cache[p] += grads[p]**2\n",
    "                    dx = -(learning_rate*grads[p])/np.sqrt(self.step_cache[p] + smooth_eps)\n",
    "                    \n",
    "                self.model[p] += dx\n",
    "\n",
    "        out = {}\n",
    "        out['cost'] = cost\n",
    "        return out\n",
    "    \n",
    "    \"\"\" prediction \"\"\"\n",
    "    def predict(self, Xs, params, **kwargs):\n",
    "        Ys, caches = self.fwdPass(Xs, params, predict_model=True)\n",
    "        pred_action = np.argmax(Ys)\n",
    "        \n",
    "        return pred_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentDQN(Agent):\n",
    "    def __init__(self, movie_dict=None, act_set=None, slot_set=None, params=None):\n",
    "        self.movie_dict = movie_dict\n",
    "        self.act_set = act_set\n",
    "        self.slot_set = slot_set\n",
    "        self.act_cardinality = len(act_set.keys())\n",
    "        self.slot_cardinality = len(slot_set.keys())\n",
    "        \n",
    "        self.feasible_actions = feasible_actions\n",
    "        self.num_actions = len(self.feasible_actions)\n",
    "        \n",
    "        self.epsilon = params['epsilon']\n",
    "        self.agent_run_mode = params['agent_run_mode']\n",
    "        self.agent_act_level = params['agent_act_level']\n",
    "        self.experience_replay_pool = [] #experience replay pool <s_t, a_t, r_t, s_t+1>\n",
    "        \n",
    "        self.experience_replay_pool_size = params.get('experience_replay_pool_size', 1000)\n",
    "        self.hidden_size = params.get('dqn_hidden_size', 60)\n",
    "        self.gamma = params.get('gamma', 0.9)\n",
    "        self.predict_mode = params.get('predict_mode', False)\n",
    "        self.warm_start = params.get('warm_start', 0)\n",
    "        \n",
    "        self.max_turn = params['max_turn'] + 4\n",
    "        self.state_dimension = 2 * self.act_cardinality + 7 * self.slot_cardinality + 3 + self.max_turn\n",
    "        \n",
    "        self.dqn = DQN(self.state_dimension, self.hidden_size, self.num_actions)\n",
    "        self.clone_dqn = copy.deepcopy(self.dqn)\n",
    "        \n",
    "        self.cur_bellman_err = 0\n",
    "                \n",
    "        # Prediction Mode: load trained DQN model\n",
    "        if params['trained_model_path'] != None:\n",
    "            self.dqn.model = copy.deepcopy(self.load_trained_DQN(params['trained_model_path']))\n",
    "            self.clone_dqn = copy.deepcopy(self.dqn)\n",
    "            self.predict_mode = True\n",
    "            self.warm_start = 2\n",
    "            \n",
    "            \n",
    "    def initialize_episode(self):\n",
    "        \"\"\" Initialize a new episode. This function is called every time a new episode is run. \"\"\"\n",
    "        \n",
    "        self.current_slot_id = 0\n",
    "        self.phase = 0\n",
    "        self.request_set = ['moviename', 'starttime', 'city', 'date', 'theater', 'numberofpeople']\n",
    "    \n",
    "    \n",
    "    def state_to_action(self, state):\n",
    "        \"\"\" DQN: Input state, output action \"\"\"\n",
    "        \n",
    "        self.representation = self.prepare_state_representation(state)\n",
    "        self.action = self.run_policy(self.representation)\n",
    "        act_slot_response = copy.deepcopy(self.feasible_actions[self.action])\n",
    "        return {'act_slot_response': act_slot_response, 'act_slot_value_response': None}\n",
    "        \n",
    "    \n",
    "    def prepare_state_representation(self, state):\n",
    "        \"\"\" Create the representation for each state \"\"\"\n",
    "        \n",
    "        user_action = state['user_action']\n",
    "        current_slots = state['current_slots']\n",
    "        kb_results_dict = state['kb_results_dict']\n",
    "        agent_last = state['agent_action']\n",
    "        \n",
    "        ########################################################################\n",
    "        #   Create one-hot of acts to represent the current user action\n",
    "        ########################################################################\n",
    "        user_act_rep =  np.zeros((1, self.act_cardinality))\n",
    "        user_act_rep[0,self.act_set[user_action['diaact']]] = 1.0\n",
    "\n",
    "        ########################################################################\n",
    "        #     Create bag of inform slots representation to represent the current user action\n",
    "        ########################################################################\n",
    "        user_inform_slots_rep = np.zeros((1, self.slot_cardinality))\n",
    "        for slot in user_action['inform_slots'].keys():\n",
    "            user_inform_slots_rep[0,self.slot_set[slot]] = 1.0\n",
    "\n",
    "        ########################################################################\n",
    "        #   Create bag of request slots representation to represent the current user action\n",
    "        ########################################################################\n",
    "        user_request_slots_rep = np.zeros((1, self.slot_cardinality))\n",
    "        for slot in user_action['request_slots'].keys():\n",
    "            user_request_slots_rep[0, self.slot_set[slot]] = 1.0\n",
    "\n",
    "        ########################################################################\n",
    "        #   Creat bag of filled_in slots based on the current_slots\n",
    "        ########################################################################\n",
    "        current_slots_rep = np.zeros((1, self.slot_cardinality))\n",
    "        for slot in current_slots['inform_slots']:\n",
    "            current_slots_rep[0, self.slot_set[slot]] = 1.0\n",
    "\n",
    "        ########################################################################\n",
    "        #   Encode last agent act\n",
    "        ########################################################################\n",
    "        agent_act_rep = np.zeros((1,self.act_cardinality))\n",
    "        if agent_last:\n",
    "            agent_act_rep[0, self.act_set[agent_last['diaact']]] = 1.0\n",
    "\n",
    "        ########################################################################\n",
    "        #   Encode last agent inform slots\n",
    "        ########################################################################\n",
    "        agent_inform_slots_rep = np.zeros((1, self.slot_cardinality))\n",
    "        if agent_last:\n",
    "            for slot in agent_last['inform_slots'].keys():\n",
    "                agent_inform_slots_rep[0,self.slot_set[slot]] = 1.0\n",
    "\n",
    "        ########################################################################\n",
    "        #   Encode last agent request slots\n",
    "        ########################################################################\n",
    "        agent_request_slots_rep = np.zeros((1, self.slot_cardinality))\n",
    "        if agent_last:\n",
    "            for slot in agent_last['request_slots'].keys():\n",
    "                agent_request_slots_rep[0,self.slot_set[slot]] = 1.0\n",
    "        \n",
    "        turn_rep = np.zeros((1,1)) + state['turn'] / 10.\n",
    "\n",
    "        ########################################################################\n",
    "        #  One-hot representation of the turn count?\n",
    "        ########################################################################\n",
    "        turn_onehot_rep = np.zeros((1, self.max_turn))\n",
    "        turn_onehot_rep[0, state['turn']] = 1.0\n",
    "\n",
    "        ########################################################################\n",
    "        #   Representation of KB results (scaled counts)\n",
    "        ########################################################################\n",
    "        kb_count_rep = np.zeros((1, self.slot_cardinality + 1)) + kb_results_dict['matching_all_constraints'] / 100.\n",
    "        for slot in kb_results_dict:\n",
    "            if slot in self.slot_set:\n",
    "                kb_count_rep[0, self.slot_set[slot]] = kb_results_dict[slot] / 100.\n",
    "\n",
    "        ########################################################################\n",
    "        #   Representation of KB results (binary)\n",
    "        ########################################################################\n",
    "        kb_binary_rep = np.zeros((1, self.slot_cardinality + 1)) + np.sum( kb_results_dict['matching_all_constraints'] > 0.)\n",
    "        for slot in kb_results_dict:\n",
    "            if slot in self.slot_set:\n",
    "                kb_binary_rep[0, self.slot_set[slot]] = np.sum( kb_results_dict[slot] > 0.)\n",
    "\n",
    "        self.final_representation = np.hstack([user_act_rep, user_inform_slots_rep, user_request_slots_rep, agent_act_rep, agent_inform_slots_rep, agent_request_slots_rep, current_slots_rep, turn_rep, turn_onehot_rep, kb_binary_rep, kb_count_rep])\n",
    "        return self.final_representation\n",
    "      \n",
    "    def run_policy(self, representation):\n",
    "        \"\"\" epsilon-greedy policy \"\"\"\n",
    "        \n",
    "        if random.random() < self.epsilon:\n",
    "            return random.randint(0, self.num_actions - 1)\n",
    "        else:\n",
    "            if self.warm_start == 1:\n",
    "                if len(self.experience_replay_pool) > self.experience_replay_pool_size:\n",
    "                    self.warm_start = 2\n",
    "                return self.rule_policy()\n",
    "            else:\n",
    "                return self.dqn.predict(representation, {}, predict_model=True)\n",
    "    \n",
    "    def rule_policy(self):\n",
    "        \"\"\" Rule Policy \"\"\"\n",
    "        \n",
    "        if self.current_slot_id < len(self.request_set):\n",
    "            slot = self.request_set[self.current_slot_id]\n",
    "            self.current_slot_id += 1\n",
    "\n",
    "            act_slot_response = {}\n",
    "            act_slot_response['diaact'] = \"request\"\n",
    "            act_slot_response['inform_slots'] = {}\n",
    "            act_slot_response['request_slots'] = {slot: \"UNK\"}\n",
    "        elif self.phase == 0:\n",
    "            act_slot_response = {'diaact': \"inform\", 'inform_slots': {'taskcomplete': \"PLACEHOLDER\"}, 'request_slots': {} }\n",
    "            self.phase += 1\n",
    "        elif self.phase == 1:\n",
    "            act_slot_response = {'diaact': \"thanks\", 'inform_slots': {}, 'request_slots': {} }\n",
    "                \n",
    "        return self.action_index(act_slot_response)\n",
    "    \n",
    "    def action_index(self, act_slot_response):\n",
    "        \"\"\" Return the index of action \"\"\"\n",
    "        \n",
    "        for (i, action) in enumerate(self.feasible_actions):\n",
    "            if act_slot_response == action:\n",
    "                return i\n",
    "        print act_slot_response\n",
    "        raise Exception(\"action index not found\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def register_experience_replay_tuple(self, s_t, a_t, reward, s_tplus1, episode_over):\n",
    "        \"\"\" Register feedback from the environment, to be stored as future training data \"\"\"\n",
    "        \n",
    "        state_t_rep = self.prepare_state_representation(s_t)\n",
    "        action_t = self.action\n",
    "        reward_t = reward\n",
    "        state_tplus1_rep = self.prepare_state_representation(s_tplus1)\n",
    "        training_example = (state_t_rep, action_t, reward_t, state_tplus1_rep, episode_over)\n",
    "        \n",
    "        if self.predict_mode == False: # Training Mode\n",
    "            if self.warm_start == 1:\n",
    "                self.experience_replay_pool.append(training_example)\n",
    "        else: # Prediction Mode\n",
    "            self.experience_replay_pool.append(training_example)\n",
    "    \n",
    "    def train(self, batch_size=1, num_batches=100):\n",
    "        \"\"\" Train DQN with experience replay \"\"\"\n",
    "        \n",
    "        for iter_batch in range(num_batches):\n",
    "            self.cur_bellman_err = 0\n",
    "            for iter in range(len(self.experience_replay_pool)/(batch_size)):\n",
    "                batch = [random.choice(self.experience_replay_pool) for i in xrange(batch_size)]\n",
    "                batch_struct = self.dqn.singleBatch(batch, {'gamma': self.gamma}, self.clone_dqn)\n",
    "                self.cur_bellman_err += batch_struct['cost']['total_cost']\n",
    "            \n",
    "            print (\"cur bellman err %.4f, experience replay pool %s\" % (float(self.cur_bellman_err)/len(self.experience_replay_pool), len(self.experience_replay_pool)))\n",
    "            \n",
    "            \n",
    "    ################################################################################\n",
    "    #    Debug Functions\n",
    "    ################################################################################\n",
    "    def save_experience_replay_to_file(self, path):\n",
    "        \"\"\" Save the experience replay pool to a file \"\"\"\n",
    "        \n",
    "        try:\n",
    "            pickle.dump(self.experience_replay_pool, open(path, \"wb\"))\n",
    "            print 'saved model in %s' % (path, )\n",
    "        except Exception, e:\n",
    "            print 'Error: Writing model fails: %s' % (path, )\n",
    "            print e         \n",
    "    \n",
    "    def load_experience_replay_from_file(self, path):\n",
    "        \"\"\" Load the experience replay pool from a file\"\"\"\n",
    "        \n",
    "        self.experience_replay_pool = pickle.load(open(path, 'rb'))\n",
    "    \n",
    "             \n",
    "    def load_trained_DQN(self, path):\n",
    "        \"\"\" Load the trained DQN from a file \"\"\"\n",
    "        \n",
    "        trained_file = pickle.load(open(path, 'rb'))\n",
    "        model = trained_file['model']\n",
    "        \n",
    "        print \"trained DQN Parameters:\", json.dumps(trained_file['params'], indent=2)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if agt == 0:\n",
    "    agent = AgentCmd(movie_kb, act_set, slot_set, agent_params)\n",
    "elif agt == 1:\n",
    "    agent = InformAgent(movie_kb, act_set, slot_set, agent_params)\n",
    "elif agt == 2:\n",
    "    agent = RequestAllAgent(movie_kb, act_set, slot_set, agent_params)\n",
    "elif agt == 3:\n",
    "    agent = RandomAgent(movie_kb, act_set, slot_set, agent_params)\n",
    "elif agt == 4:\n",
    "    agent = EchoAgent(movie_kb, act_set, slot_set, agent_params)\n",
    "elif agt == 5:\n",
    "    agent = RequestBasicsAgent(movie_kb, act_set, slot_set, agent_params)\n",
    "elif agt == 9:\n",
    "    agent = AgentDQN(movie_kb, act_set, slot_set, agent_params)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "usersim_params = {}\n",
    "usersim_params['max_turn'] = max_turn\n",
    "usersim_params['slot_err_probability'] = params['slot_err_prob']\n",
    "usersim_params['slot_err_mode'] = params['slot_err_mode']\n",
    "usersim_params['intent_err_probability'] = params['intent_err_prob']\n",
    "usersim_params['simulator_run_mode'] = params['run_mode']\n",
    "usersim_params['simulator_act_level'] = params['act_level']\n",
    "usersim_params['learning_phase'] = params['learning_phase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserSimulator:\n",
    "    \"\"\" Parent class for all user sims to inherit from \"\"\"\n",
    "\n",
    "    def __init__(self, movie_dict=None, act_set=None, slot_set=None, start_set=None, params=None):\n",
    "        \"\"\" Constructor shared by all user simulators \"\"\"\n",
    "        \n",
    "        self.movie_dict = movie_dict\n",
    "        self.act_set = act_set\n",
    "        self.slot_set = slot_set\n",
    "        self.start_set = start_set\n",
    "        \n",
    "        self.max_turn = params['max_turn']\n",
    "        self.slot_err_probability = params['slot_err_probability']\n",
    "        self.slot_err_mode = params['slot_err_mode']\n",
    "        self.intent_err_probability = params['intent_err_probability']\n",
    "        \n",
    "\n",
    "    def initialize_episode(self):\n",
    "        \"\"\" Initialize a new episode (dialog)\"\"\"\n",
    "\n",
    "        print \"initialize episode called, generating goal\"\n",
    "        self.goal =  random.choice(self.start_set)\n",
    "        self.goal['request_slots']['ticket'] = 'UNK'\n",
    "        episode_over, user_action = self._sample_action()\n",
    "        assert (episode_over != 1),' but we just started'\n",
    "        return user_action\n",
    "\n",
    "\n",
    "    def next(self, system_action):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    def set_nlg_model(self, nlg_model):\n",
    "        self.nlg_model = nlg_model  \n",
    "    \n",
    "    def set_nlu_model(self, nlu_model):\n",
    "        self.nlu_model = nlu_model\n",
    "    \n",
    "    \n",
    "    \n",
    "    def add_nl_to_action(self, user_action):\n",
    "        \"\"\" Add NL to User Dia_Act \"\"\"\n",
    "        \n",
    "        user_nlg_sentence = self.nlg_model.convert_diaact_to_nl(user_action, 'usr')\n",
    "        user_action['nl'] = user_nlg_sentence\n",
    "        \n",
    "        if self.simulator_act_level == 1:\n",
    "            user_nlu_res = self.nlu_model.generate_dia_act(user_action['nl']) # NLU\n",
    "            if user_nlu_res != None:\n",
    "                #user_nlu_res['diaact'] = user_action['diaact'] # or not?\n",
    "                user_action.update(user_nlu_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuleSimulator(UserSimulator):\n",
    "    \"\"\" A rule-based user simulator for testing dialog policy \"\"\"\n",
    "    \n",
    "    def __init__(self, movie_dict=None, act_set=None, slot_set=None, start_set=None, params=None):\n",
    "        \"\"\" Constructor shared by all user simulators \"\"\"\n",
    "        \n",
    "        self.movie_dict = movie_dict\n",
    "        self.act_set = act_set\n",
    "        self.slot_set = slot_set\n",
    "        self.start_set = start_set\n",
    "        \n",
    "        self.max_turn = params['max_turn']\n",
    "        self.slot_err_probability = params['slot_err_probability']\n",
    "        self.slot_err_mode = params['slot_err_mode']\n",
    "        self.intent_err_probability = params['intent_err_probability']\n",
    "        \n",
    "        self.simulator_run_mode = params['simulator_run_mode']\n",
    "        self.simulator_act_level = params['simulator_act_level']\n",
    "        \n",
    "        self.learning_phase = params['learning_phase']\n",
    "    \n",
    "    def initialize_episode(self):\n",
    "        \"\"\" Initialize a new episode (dialog) \n",
    "        state['history_slots']: keeps all the informed_slots\n",
    "        state['rest_slots']: keep all the slots (which is still in the stack yet)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.state = {}\n",
    "        self.state['history_slots'] = {}\n",
    "        self.state['inform_slots'] = {}\n",
    "        self.state['request_slots'] = {}\n",
    "        self.state['rest_slots'] = []\n",
    "        self.state['turn'] = 0\n",
    "        \n",
    "        self.episode_over = False\n",
    "        self.dialog_status = NO_OUTCOME_YET\n",
    "        \n",
    "        #self.goal =  random.choice(self.start_set)\n",
    "        self.goal = self._sample_goal(self.start_set)\n",
    "        self.goal['request_slots']['ticket'] = 'UNK'\n",
    "        self.constraint_check = CONSTRAINT_CHECK_FAILURE\n",
    "  \n",
    "        \"\"\" Debug: build a fake goal mannually \"\"\"\n",
    "        #self.debug_falk_goal()\n",
    "        \n",
    "        # sample first action\n",
    "        user_action = self._sample_action()\n",
    "        assert (self.episode_over != 1),' but we just started'\n",
    "        return user_action  \n",
    "        \n",
    "    def _sample_action(self):\n",
    "        \"\"\" randomly sample a start action based on user goal \"\"\"\n",
    "        \n",
    "        self.state['diaact'] = random.choice(start_dia_acts.keys())\n",
    "        \n",
    "        # \"sample\" informed slots\n",
    "        if len(self.goal['inform_slots']) > 0:\n",
    "            known_slot = random.choice(self.goal['inform_slots'].keys())\n",
    "            self.state['inform_slots'][known_slot] = self.goal['inform_slots'][known_slot]\n",
    "\n",
    "            if 'moviename' in self.goal['inform_slots'].keys(): # 'moviename' must appear in the first user turn\n",
    "                self.state['inform_slots']['moviename'] = self.goal['inform_slots']['moviename']\n",
    "                \n",
    "            for slot in self.goal['inform_slots'].keys():\n",
    "                if known_slot == slot or slot == 'moviename': continue\n",
    "                self.state['rest_slots'].append(slot)\n",
    "        \n",
    "        self.state['rest_slots'].extend(self.goal['request_slots'].keys())\n",
    "        \n",
    "        # \"sample\" a requested slot\n",
    "        request_slot_set = list(self.goal['request_slots'].keys())\n",
    "        request_slot_set.remove('ticket')\n",
    "        if len(request_slot_set) > 0:\n",
    "            request_slot = random.choice(request_slot_set)\n",
    "        else:\n",
    "            request_slot = 'ticket'\n",
    "        self.state['request_slots'][request_slot] = 'UNK'\n",
    "        \n",
    "        if len(self.state['request_slots']) == 0:\n",
    "            self.state['diaact'] = 'inform'\n",
    "\n",
    "        if (self.state['diaact'] in ['thanks','closing']): self.episode_over = True #episode_over = True\n",
    "        else: self.episode_over = False #episode_over = False\n",
    "\n",
    "        sample_action = {}\n",
    "        sample_action['diaact'] = self.state['diaact']\n",
    "        sample_action['inform_slots'] = self.state['inform_slots']\n",
    "        sample_action['request_slots'] = self.state['request_slots']\n",
    "        sample_action['turn'] = self.state['turn']\n",
    "        \n",
    "        self.add_nl_to_action(sample_action)\n",
    "        return sample_action\n",
    "    \n",
    "    def _sample_goal(self, goal_set):\n",
    "        \"\"\" sample a user goal  \"\"\"\n",
    "        \n",
    "        sample_goal = random.choice(self.start_set[self.learning_phase])\n",
    "        return sample_goal\n",
    "    \n",
    "    \n",
    "    def corrupt(self, user_action):\n",
    "        \"\"\" Randomly corrupt an action with error probs (slot_err_probability and slot_err_mode) on Slot and Intent (intent_err_probability). \"\"\"\n",
    "        \n",
    "        for slot in user_action['inform_slots'].keys():\n",
    "            slot_err_prob_sample = random.random()\n",
    "            if slot_err_prob_sample < self.slot_err_probability: # add noise for slot level\n",
    "                if self.slot_err_mode == 0: # replace the slot_value only\n",
    "                    if slot in self.movie_dict.keys(): user_action['inform_slots'][slot] = random.choice(self.movie_dict[slot])\n",
    "                elif self.slot_err_mode == 1: # combined\n",
    "                    slot_err_random = random.random()\n",
    "                    if slot_err_random <= 0.33:\n",
    "                        if slot in self.movie_dict.keys(): user_action['inform_slots'][slot] = random.choice(self.movie_dict[slot])\n",
    "                    elif slot_err_random > 0.33 and slot_err_random <= 0.66:\n",
    "                        del user_action['inform_slots'][slot]\n",
    "                        random_slot = random.choice(self.movie_dict.keys())\n",
    "                        user_action[random_slot] = random.choice(self.movie_dict[random_slot])\n",
    "                    else:\n",
    "                        del user_action['inform_slots'][slot]\n",
    "                elif self.slot_err_mode == 2: #replace slot and its values\n",
    "                    del user_action['inform_slots'][slot]\n",
    "                    random_slot = random.choice(self.movie_dict.keys())\n",
    "                    user_action[random_slot] = random.choice(self.movie_dict[random_slot])\n",
    "                elif self.slot_err_mode == 3: # delete the slot\n",
    "                    del user_action['inform_slots'][slot]\n",
    "                    \n",
    "        intent_err_sample = random.random()\n",
    "        if intent_err_sample < self.intent_err_probability: # add noise for intent level\n",
    "            user_action['diaact'] = random.choice(self.act_set.keys())\n",
    "    \n",
    "    def debug_falk_goal(self):\n",
    "        \"\"\" Debug function: build a fake goal mannually (Can be moved in future) \"\"\"\n",
    "        \n",
    "        self.goal['inform_slots'].clear()\n",
    "        #self.goal['inform_slots']['city'] = 'seattle'\n",
    "        self.goal['inform_slots']['numberofpeople'] = '2'\n",
    "        #self.goal['inform_slots']['theater'] = 'amc pacific place 11 theater'\n",
    "        #self.goal['inform_slots']['starttime'] = '10:00 pm'\n",
    "        #self.goal['inform_slots']['date'] = 'tomorrow'\n",
    "        self.goal['inform_slots']['moviename'] = 'zoology'\n",
    "        self.goal['inform_slots']['distanceconstraints'] = 'close to 95833'\n",
    "        self.goal['request_slots'].clear()\n",
    "        self.goal['request_slots']['ticket'] = 'UNK'\n",
    "        self.goal['request_slots']['theater'] = 'UNK'\n",
    "        self.goal['request_slots']['starttime'] = 'UNK'\n",
    "        self.goal['request_slots']['date'] = 'UNK'\n",
    "        \n",
    "    def next(self, system_action):\n",
    "        \"\"\" Generate next User Action based on last System Action \"\"\"\n",
    "        \n",
    "        self.state['turn'] += 2\n",
    "        self.episode_over = False\n",
    "        self.dialog_status = NO_OUTCOME_YET\n",
    "        \n",
    "        sys_act = system_action['diaact']\n",
    "        \n",
    "        if (self.max_turn > 0 and self.state['turn'] > self.max_turn):\n",
    "            self.dialog_status = FAILED_DIALOG\n",
    "            self.episode_over = True\n",
    "            self.state['diaact'] = \"closing\"\n",
    "        else:\n",
    "            self.state['history_slots'].update(self.state['inform_slots'])\n",
    "            self.state['inform_slots'].clear()\n",
    "\n",
    "            if sys_act == \"inform\":\n",
    "                self.response_inform(system_action)\n",
    "            elif sys_act == \"multiple_choice\":\n",
    "                self.response_multiple_choice(system_action)\n",
    "            elif sys_act == \"request\":\n",
    "                self.response_request(system_action) \n",
    "            elif sys_act == \"thanks\":\n",
    "                self.response_thanks(system_action)\n",
    "            elif sys_act == \"confirm_answer\":\n",
    "                self.response_confirm_answer(system_action)\n",
    "            elif sys_act == \"closing\":\n",
    "                self.episode_over = True\n",
    "                self.state['diaact'] = \"thanks\"\n",
    "\n",
    "        self.corrupt(self.state)\n",
    "        \n",
    "        response_action = {}\n",
    "        response_action['diaact'] = self.state['diaact']\n",
    "        response_action['inform_slots'] = self.state['inform_slots']\n",
    "        response_action['request_slots'] = self.state['request_slots']\n",
    "        response_action['turn'] = self.state['turn']\n",
    "        response_action['nl'] = \"\"\n",
    "        \n",
    "        # add NL to dia_act\n",
    "        self.add_nl_to_action(response_action)                       \n",
    "        return response_action, self.episode_over, self.dialog_status\n",
    "    \n",
    "    \n",
    "    def response_confirm_answer(self, system_action):\n",
    "        \"\"\" Response for Confirm_Answer (System Action) \"\"\"\n",
    "    \n",
    "        if len(self.state['rest_slots']) > 0:\n",
    "            request_slot = random.choice(self.state['rest_slots'])\n",
    "\n",
    "            if request_slot in self.goal['request_slots'].keys():\n",
    "                self.state['diaact'] = \"request\"\n",
    "                self.state['request_slots'][request_slot] = \"UNK\"\n",
    "            elif request_slot in self.goal['inform_slots'].keys():\n",
    "                self.state['diaact'] = \"inform\"\n",
    "                self.state['inform_slots'][request_slot] = self.goal['inform_slots'][request_slot]\n",
    "                if request_slot in self.state['rest_slots']:\n",
    "                    self.state['rest_slots'].remove(request_slot)\n",
    "        else:\n",
    "            self.state['diaact'] = \"thanks\"\n",
    "            \n",
    "    def response_thanks(self, system_action):\n",
    "        \"\"\" Response for Thanks (System Action) \"\"\"\n",
    "        \n",
    "        self.episode_over = True\n",
    "        self.dialog_status = SUCCESS_DIALOG\n",
    "\n",
    "        request_slot_set = copy.deepcopy(self.state['request_slots'].keys())\n",
    "        if 'ticket' in request_slot_set:\n",
    "            request_slot_set.remove('ticket')\n",
    "        rest_slot_set = copy.deepcopy(self.state['rest_slots'])\n",
    "        if 'ticket' in rest_slot_set:\n",
    "            rest_slot_set.remove('ticket')\n",
    "\n",
    "        if len(request_slot_set) > 0 or len(rest_slot_set) > 0:\n",
    "            self.dialog_status = FAILED_DIALOG\n",
    "\n",
    "        for info_slot in self.state['history_slots'].keys():\n",
    "            if self.state['history_slots'][info_slot] == NO_VALUE_MATCH:\n",
    "                self.dialog_status = FAILED_DIALOG\n",
    "            if info_slot in self.goal['inform_slots'].keys():\n",
    "                if self.state['history_slots'][info_slot] != self.goal['inform_slots'][info_slot]:\n",
    "                    self.dialog_status = FAILED_DIALOG\n",
    "\n",
    "        if 'ticket' in system_action['inform_slots'].keys():\n",
    "            if system_action['inform_slots']['ticket'] == dialog_config.NO_VALUE_MATCH:\n",
    "                self.dialog_status = FAILED_DIALOG\n",
    "                \n",
    "        if self.constraint_check == CONSTRAINT_CHECK_FAILURE:\n",
    "            self.dialog_status = FAILED_DIALOG\n",
    "    \n",
    "    def response_request(self, system_action):\n",
    "        \"\"\" Response for Request (System Action) \"\"\"\n",
    "        \n",
    "        if len(system_action['request_slots'].keys()) > 0:\n",
    "            slot = system_action['request_slots'].keys()[0] # only one slot\n",
    "            if slot in self.goal['inform_slots'].keys(): # request slot in user's constraints  #and slot not in self.state['request_slots'].keys():\n",
    "                self.state['inform_slots'][slot] = self.goal['inform_slots'][slot]\n",
    "                self.state['diaact'] = \"inform\"\n",
    "                if slot in self.state['rest_slots']: self.state['rest_slots'].remove(slot)\n",
    "                if slot in self.state['request_slots'].keys(): del self.state['request_slots'][slot]\n",
    "                self.state['request_slots'].clear()\n",
    "            elif slot in self.goal['request_slots'].keys() and slot not in self.state['rest_slots'] and slot in self.state['history_slots'].keys(): # the requested slot has been answered\n",
    "                self.state['inform_slots'][slot] = self.state['history_slots'][slot]\n",
    "                self.state['request_slots'].clear()\n",
    "                self.state['diaact'] = \"inform\"\n",
    "            elif slot in self.goal['request_slots'].keys() and slot in self.state['rest_slots']: # request slot in user's goal's request slots, and not answered yet\n",
    "                self.state['diaact'] = \"request\" # \"confirm_question\"\n",
    "                self.state['request_slots'][slot] = \"UNK\"\n",
    "\n",
    "                ########################################################################\n",
    "                # Inform the rest of informable slots\n",
    "                ########################################################################\n",
    "                for info_slot in self.state['rest_slots']:\n",
    "                    if info_slot in self.goal['inform_slots'].keys():\n",
    "                        self.state['inform_slots'][info_slot] = self.goal['inform_slots'][info_slot]\n",
    "\n",
    "                for info_slot in self.state['inform_slots'].keys():\n",
    "                    if info_slot in self.state['rest_slots']:\n",
    "                        self.state['rest_slots'].remove(info_slot)\n",
    "            else:\n",
    "                if len(self.state['request_slots']) == 0 and len(self.state['rest_slots']) == 0:\n",
    "                    self.state['diaact'] = \"thanks\"\n",
    "                else:\n",
    "                    self.state['diaact'] = \"inform\"\n",
    "                self.state['inform_slots'][slot] = I_DO_NOT_CARE\n",
    "        else: # this case should not appear\n",
    "            if len(self.state['rest_slots']) > 0:\n",
    "                random_slot = random.choice(self.state['rest_slots'])\n",
    "                if random_slot in self.goal['inform_slots'].keys():\n",
    "                    self.state['inform_slots'][random_slot] = self.goal['inform_slots'][random_slot]\n",
    "                    self.state['rest_slots'].remove(random_slot)\n",
    "                    self.state['diaact'] = \"inform\"\n",
    "                elif random_slot in self.goal['request_slots'].keys():\n",
    "                    self.state['request_slots'][random_slot] = self.goal['request_slots'][random_slot]\n",
    "                    self.state['diaact'] = \"request\"\n",
    "\n",
    "    def response_multiple_choice(self, system_action):\n",
    "        \"\"\" Response for Multiple_Choice (System Action) \"\"\"\n",
    "        \n",
    "        slot = system_action['inform_slots'].keys()[0]\n",
    "        if slot in self.goal['inform_slots'].keys():\n",
    "            self.state['inform_slots'][slot] = self.goal['inform_slots'][slot]\n",
    "        elif slot in self.goal['request_slots'].keys():\n",
    "            self.state['inform_slots'][slot] = random.choice(system_action['inform_slots'][slot])\n",
    "\n",
    "        self.state['diaact'] = \"inform\"\n",
    "        if slot in self.state['rest_slots']: self.state['rest_slots'].remove(slot)\n",
    "        if slot in self.state['request_slots'].keys(): del self.state['request_slots'][slot]\n",
    "        \n",
    "    def response_inform(self, system_action):\n",
    "        \"\"\" Response for Inform (System Action) \"\"\"\n",
    "        \n",
    "        if 'taskcomplete' in system_action['inform_slots'].keys(): # check all the constraints from agents with user goal\n",
    "            self.state['diaact'] = \"thanks\"\n",
    "            #if 'ticket' in self.state['rest_slots']: self.state['request_slots']['ticket'] = 'UNK'\n",
    "            self.constraint_check = CONSTRAINT_CHECK_SUCCESS\n",
    "                    \n",
    "            if system_action['inform_slots']['taskcomplete'] == NO_VALUE_MATCH:\n",
    "                self.state['history_slots']['ticket'] = NO_VALUE_MATCH\n",
    "                if 'ticket' in self.state['rest_slots']: self.state['rest_slots'].remove('ticket')\n",
    "                if 'ticket' in self.state['request_slots'].keys(): del self.state['request_slots']['ticket']\n",
    "                    \n",
    "            for slot in self.goal['inform_slots'].keys():\n",
    "                #  Deny, if the answers from agent can not meet the constraints of user\n",
    "                if slot not in system_action['inform_slots'].keys() or (self.goal['inform_slots'][slot].lower() != system_action['inform_slots'][slot].lower()):\n",
    "                    self.state['diaact'] = \"deny\"\n",
    "                    self.state['request_slots'].clear()\n",
    "                    self.state['inform_slots'].clear()\n",
    "                    self.constraint_check = CONSTRAINT_CHECK_FAILURE\n",
    "                    break\n",
    "        else:\n",
    "            for slot in system_action['inform_slots'].keys():\n",
    "                self.state['history_slots'][slot] = system_action['inform_slots'][slot]\n",
    "                        \n",
    "                if slot in self.goal['inform_slots'].keys():\n",
    "                    if system_action['inform_slots'][slot] == self.goal['inform_slots'][slot]:\n",
    "                        if slot in self.state['rest_slots']: self.state['rest_slots'].remove(slot)\n",
    "                                \n",
    "                        if len(self.state['request_slots']) > 0:\n",
    "                            self.state['diaact'] = \"request\"\n",
    "                        elif len(self.state['rest_slots']) > 0:\n",
    "                            rest_slot_set = copy.deepcopy(self.state['rest_slots'])\n",
    "                            if 'ticket' in rest_slot_set:\n",
    "                                rest_slot_set.remove('ticket')\n",
    "\n",
    "                            if len(rest_slot_set) > 0:\n",
    "                                inform_slot = random.choice(rest_slot_set) # self.state['rest_slots']\n",
    "                                if inform_slot in self.goal['inform_slots'].keys():\n",
    "                                    self.state['inform_slots'][inform_slot] = self.goal['inform_slots'][inform_slot]\n",
    "                                    self.state['diaact'] = \"inform\"\n",
    "                                    self.state['rest_slots'].remove(inform_slot)\n",
    "                                elif inform_slot in self.goal['request_slots'].keys():\n",
    "                                    self.state['request_slots'][inform_slot] = 'UNK'\n",
    "                                    self.state['diaact'] = \"request\"\n",
    "                            else:\n",
    "                                self.state['request_slots']['ticket'] = 'UNK'\n",
    "                                self.state['diaact'] = \"request\"\n",
    "                        else: # how to reply here?\n",
    "                            self.state['diaact'] = \"thanks\" # replies \"closing\"? or replies \"confirm_answer\"\n",
    "                    else: # != value  Should we deny here or ?\n",
    "                        ########################################################################\n",
    "                        # TODO When agent informs(slot=value), where the value is different with the constraint in user goal, Should we deny or just inform the correct value?\n",
    "                        ########################################################################\n",
    "                        self.state['diaact'] = \"inform\"\n",
    "                        self.state['inform_slots'][slot] = self.goal['inform_slots'][slot]\n",
    "                        if slot in self.state['rest_slots']: self.state['rest_slots'].remove(slot)\n",
    "                else:\n",
    "                    if slot in self.state['rest_slots']:\n",
    "                        self.state['rest_slots'].remove(slot)\n",
    "                    if slot in self.state['request_slots'].keys():\n",
    "                        del self.state['request_slots'][slot]\n",
    "\n",
    "                    if len(self.state['request_slots']) > 0:\n",
    "                        request_set = list(self.state['request_slots'].keys())\n",
    "                        if 'ticket' in request_set:\n",
    "                            request_set.remove('ticket')\n",
    "\n",
    "                        if len(request_set) > 0:\n",
    "                            request_slot = random.choice(request_set)\n",
    "                        else:\n",
    "                            request_slot = 'ticket'\n",
    "\n",
    "                        self.state['request_slots'][request_slot] = \"UNK\"\n",
    "                        self.state['diaact'] = \"request\"\n",
    "                    elif len(self.state['rest_slots']) > 0:\n",
    "                        rest_slot_set = copy.deepcopy(self.state['rest_slots'])\n",
    "                        if 'ticket' in rest_slot_set:\n",
    "                            rest_slot_set.remove('ticket')\n",
    "\n",
    "                        if len(rest_slot_set) > 0:\n",
    "                            inform_slot = random.choice(rest_slot_set) #self.state['rest_slots']\n",
    "                            if inform_slot in self.goal['inform_slots'].keys():\n",
    "                                self.state['inform_slots'][inform_slot] = self.goal['inform_slots'][inform_slot]\n",
    "                                self.state['diaact'] = \"inform\"\n",
    "                                self.state['rest_slots'].remove(inform_slot)\n",
    "                                        \n",
    "                                if 'ticket' in self.state['rest_slots']:\n",
    "                                    self.state['request_slots']['ticket'] = 'UNK'\n",
    "                                    self.state['diaact'] = \"request\"\n",
    "                            elif inform_slot in self.goal['request_slots'].keys():\n",
    "                                self.state['request_slots'][inform_slot] = self.goal['request_slots'][inform_slot]\n",
    "                                self.state['diaact'] = \"request\"\n",
    "                        else:\n",
    "                            self.state['request_slots']['ticket'] = 'UNK'\n",
    "                            self.state['diaact'] = \"request\"\n",
    "                    else:\n",
    "                        self.state['diaact'] = \"thanks\" # or replies \"confirm_answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if usr == 0:# real user\n",
    "    user_sim = RealUser(movie_dictionary, act_set, slot_set, goal_set, usersim_params)\n",
    "elif usr == 1: \n",
    "    user_sim = RuleSimulator(movie_dictionary, act_set, slot_set, goal_set, usersim_params)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decoder:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        pass\n",
    "    \n",
    "    def get_struct(self):\n",
    "        return {'model': self.model, 'update': self.update, 'regularize': self.regularize}\n",
    "    \n",
    "    \n",
    "    \"\"\" Activation Function: Sigmoid, or tanh, or ReLu\"\"\"\n",
    "    def fwdPass(self, Xs, params, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    def bwdPass(self, dY, cache):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \"\"\" Batch Forward & Backward Pass\"\"\"\n",
    "    def batchForward(self, ds, batch, params, predict_mode = False):\n",
    "        caches = []\n",
    "        Ys = []\n",
    "        for i,x in enumerate(batch):\n",
    "            Y, out_cache = self.fwdPass(x, params, predict_mode = predict_mode)\n",
    "            caches.append(out_cache)\n",
    "            Ys.append(Y)\n",
    "           \n",
    "        # back up information for efficient backprop\n",
    "        cache = {}\n",
    "        if not predict_mode:\n",
    "            cache['caches'] = caches\n",
    "\n",
    "        return Ys, cache\n",
    "    \n",
    "    def batchBackward(self, dY, cache):\n",
    "        caches = cache['caches']\n",
    "        grads = {}\n",
    "        for i in xrange(len(caches)):\n",
    "            single_cache = caches[i]\n",
    "            local_grads = self.bwdPass(dY[i], single_cache)\n",
    "            mergeDicts(grads, local_grads) # add up the gradients wrt model parameters\n",
    "            \n",
    "        return grads\n",
    "\n",
    "\n",
    "    \"\"\" Cost function, returns cost and gradients for model \"\"\"\n",
    "    def costFunc(self, ds, batch, params):\n",
    "        regc = params['reg_cost'] # regularization cost\n",
    "        \n",
    "        # batch forward RNN\n",
    "        Ys, caches = self.batchForward(ds, batch, params, predict_mode = False)\n",
    "        \n",
    "        loss_cost = 0.0\n",
    "        smooth_cost = 1e-15\n",
    "        dYs = []\n",
    "        \n",
    "        for i,x in enumerate(batch):\n",
    "            labels = np.array(x['labels'], dtype=int)\n",
    "            \n",
    "            # fetch the predicted probabilities\n",
    "            Y = Ys[i]\n",
    "            maxes = np.amax(Y, axis=1, keepdims=True)\n",
    "            e = np.exp(Y - maxes) # for numerical stability shift into good numerical range\n",
    "            P = e/np.sum(e, axis=1, keepdims=True)\n",
    "            \n",
    "            # Cross-Entropy Cross Function\n",
    "            loss_cost += -np.sum(np.log(smooth_cost + P[range(len(labels)), labels]))\n",
    "            \n",
    "            for iy,y in enumerate(labels):\n",
    "                P[iy,y] -= 1 # softmax derivatives\n",
    "            dYs.append(P)\n",
    "            \n",
    "        # backprop the RNN\n",
    "        grads = self.batchBackward(dYs, caches)\n",
    "        \n",
    "        # add L2 regularization cost and gradients\n",
    "        reg_cost = 0.0\n",
    "        if regc > 0:    \n",
    "            for p in self.regularize:\n",
    "                mat = self.model[p]\n",
    "                reg_cost += 0.5*regc*np.sum(mat*mat)\n",
    "                grads[p] += regc*mat\n",
    "\n",
    "        # normalize the cost and gradient by the batch size\n",
    "        batch_size = len(batch)\n",
    "        reg_cost /= batch_size\n",
    "        loss_cost /= batch_size\n",
    "        for k in grads: grads[k] /= batch_size\n",
    "\n",
    "        out = {}\n",
    "        out['cost'] = {'reg_cost' : reg_cost, 'loss_cost' : loss_cost, 'total_cost' : loss_cost + reg_cost}\n",
    "        out['grads'] = grads\n",
    "        return out\n",
    "\n",
    "\n",
    "    \"\"\" A single batch \"\"\"\n",
    "    def singleBatch(self, ds, batch, params):\n",
    "        learning_rate = params.get('learning_rate', 0.0)\n",
    "        decay_rate = params.get('decay_rate', 0.999)\n",
    "        momentum = params.get('momentum', 0)\n",
    "        grad_clip = params.get('grad_clip', 1)\n",
    "        smooth_eps = params.get('smooth_eps', 1e-8)\n",
    "        sdg_type = params.get('sdgtype', 'rmsprop')\n",
    "\n",
    "        for u in self.update:\n",
    "            if not u in self.step_cache: \n",
    "                self.step_cache[u] = np.zeros(self.model[u].shape)\n",
    "        \n",
    "        cg = self.costFunc(ds, batch, params)\n",
    "        \n",
    "        cost = cg['cost']\n",
    "        grads = cg['grads']\n",
    "        \n",
    "        # clip gradients if needed\n",
    "        if params['activation_func'] == 'relu':\n",
    "            if grad_clip > 0:\n",
    "                for p in self.update:\n",
    "                    if p in grads:\n",
    "                        grads[p] = np.minimum(grads[p], grad_clip)\n",
    "                        grads[p] = np.maximum(grads[p], -grad_clip)\n",
    "        \n",
    "        # perform parameter update\n",
    "        for p in self.update:\n",
    "            if p in grads:\n",
    "                if sdg_type == 'vanilla':\n",
    "                    if momentum > 0: dx = momentum*self.step_cache[p] - learning_rate*grads[p]\n",
    "                    else: dx = -learning_rate*grads[p]\n",
    "                    self.step_cache[p] = dx\n",
    "                elif sdg_type == 'rmsprop':\n",
    "                    self.step_cache[p] = self.step_cache[p]*decay_rate + (1.0-decay_rate)*grads[p]**2\n",
    "                    dx = -(learning_rate*grads[p])/np.sqrt(self.step_cache[p] + smooth_eps)\n",
    "                elif sdg_type == 'adgrad':\n",
    "                    self.step_cache[p] += grads[p]**2\n",
    "                    dx = -(learning_rate*grads[p])/np.sqrt(self.step_cache[p] + smooth_eps)\n",
    "                    \n",
    "                self.model[p] += dx\n",
    "\n",
    "        # create output dict and return\n",
    "        out = {}\n",
    "        out['cost'] = cost\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    \"\"\" Evaluate on the dataset[split] \"\"\"\n",
    "    def eval(self, ds, split, params):\n",
    "        acc = 0\n",
    "        total = 0\n",
    "        \n",
    "        total_cost = 0.0\n",
    "        smooth_cost = 1e-15\n",
    "        perplexity = 0\n",
    "        \n",
    "        for i, ele in enumerate(ds.split[split]):\n",
    "            #ele_reps = self.prepare_input_rep(ds, [ele], params)\n",
    "            #Ys, cache = self.fwdPass(ele_reps[0], params, predict_model=True)\n",
    "            #labels = np.array(ele_reps[0]['labels'], dtype=int)\n",
    "            \n",
    "            Ys, cache = self.fwdPass(ele, params, predict_model=True)\n",
    "            \n",
    "            maxes = np.amax(Ys, axis=1, keepdims=True)\n",
    "            e = np.exp(Ys - maxes) # for numerical stability shift into good numerical range\n",
    "            probs = e/np.sum(e, axis=1, keepdims=True)\n",
    "            \n",
    "            labels = np.array(ele['labels'], dtype=int)\n",
    "            \n",
    "            if np.all(np.isnan(probs)): probs = np.zeros(probs.shape)\n",
    "            \n",
    "            log_perplex = 0\n",
    "            log_perplex += -np.sum(np.log2(smooth_cost + probs[range(len(labels)), labels]))\n",
    "            log_perplex /= len(labels)\n",
    "            \n",
    "            loss_cost = 0\n",
    "            loss_cost += -np.sum(np.log(smooth_cost + probs[range(len(labels)), labels]))\n",
    "            \n",
    "            perplexity += log_perplex #2**log_perplex\n",
    "            total_cost += loss_cost\n",
    "            \n",
    "            pred_words_indices = np.nanargmax(probs, axis=1)\n",
    "            for index, l in enumerate(labels):\n",
    "                if pred_words_indices[index] == l:\n",
    "                    acc += 1\n",
    "            \n",
    "            total += len(labels)\n",
    "            \n",
    "        perplexity /= len(ds.split[split])    \n",
    "        total_cost /= len(ds.split[split])\n",
    "        accuracy = 0 if total == 0 else float(acc)/total\n",
    "        \n",
    "        #print (\"perplexity: %s, total_cost: %s, accuracy: %s\" % (perplexity, total_cost, accuracy))\n",
    "        result = {'perplexity': perplexity, 'cost': total_cost, 'accuracy': accuracy}\n",
    "        return result\n",
    "    \n",
    "    \n",
    "         \n",
    "    \"\"\" prediction on dataset[split] \"\"\"\n",
    "    def predict(self, ds, split, params):\n",
    "        inverse_word_dict = {ds.data['word_dict'][k]:k for k in ds.data['word_dict'].keys()}\n",
    "        for i, ele in enumerate(ds.split[split]):\n",
    "            pred_ys, pred_words = self.forward(inverse_word_dict, ele, params, predict_model=True)\n",
    "            \n",
    "            sentence = ' '.join(pred_words[:-1])\n",
    "            real_sentence = ' '.join(ele['sentence'].split(' ')[1:-1])\n",
    "            \n",
    "            if params['dia_slot_val'] == 2 or params['dia_slot_val'] == 3: \n",
    "                sentence = self.post_process(sentence, ele['slotval'], ds.data['slot_dict'])\n",
    "            \n",
    "            print 'test case', i\n",
    "            print 'real:', real_sentence\n",
    "            print 'pred:', sentence\n",
    "    \n",
    "    \"\"\" post_process to fill the slot \"\"\"\n",
    "    def post_process(self, pred_template, slot_val_dict, slot_dict):\n",
    "        sentence = pred_template\n",
    "        suffix = \"_PLACEHOLDER\"\n",
    "        \n",
    "        for slot in slot_val_dict.keys():\n",
    "            slot_vals = slot_val_dict[slot]\n",
    "            slot_placeholder = slot + suffix\n",
    "            if slot == 'result' or slot == 'numberofpeople': continue\n",
    "            for slot_val in slot_vals:\n",
    "                tmp_sentence = sentence.replace(slot_placeholder, slot_val, 1)\n",
    "                sentence = tmp_sentence\n",
    "                \n",
    "        if 'numberofpeople' in slot_val_dict.keys():\n",
    "            slot_vals = slot_val_dict['numberofpeople']\n",
    "            slot_placeholder = 'numberofpeople' + suffix\n",
    "            for slot_val in slot_vals:\n",
    "                tmp_sentence = sentence.replace(slot_placeholder, slot_val, 1)\n",
    "                sentence = tmp_sentence\n",
    "                \n",
    "        for slot in slot_dict.keys():\n",
    "            slot_placeholder = slot + suffix\n",
    "            tmp_sentence = sentence.replace(slot_placeholder, '')\n",
    "            sentence = tmp_sentence\n",
    "        \n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_decoder_tanh(decoder):\n",
    "    def __init__(self, diaact_input_size, input_size, hidden_size, output_size):\n",
    "        self.model = {}\n",
    "        # connections from diaact to hidden layer\n",
    "        self.model['Wah'] = initWeights(diaact_input_size, 4*hidden_size)\n",
    "        self.model['bah'] = np.zeros((1, 4*hidden_size))\n",
    "        \n",
    "        # Recurrent weights: take x_t, h_{t-1}, and bias unit, and produce the 3 gates and the input to cell signal\n",
    "        self.model['WLSTM'] = initWeights(input_size + hidden_size + 1, 4*hidden_size)\n",
    "        # Hidden-Output Connections\n",
    "        self.model['Wd'] = initWeights(hidden_size, output_size)*0.1\n",
    "        self.model['bd'] = np.zeros((1, output_size))\n",
    "\n",
    "        self.update = ['Wah', 'bah', 'WLSTM', 'Wd', 'bd']\n",
    "        self.regularize = ['Wah', 'WLSTM', 'Wd']\n",
    "\n",
    "        self.step_cache = {}\n",
    "        \n",
    "    \"\"\" Activation Function: Sigmoid, or tanh, or ReLu \"\"\"\n",
    "    def fwdPass(self, Xs, params, **kwargs):\n",
    "        predict_mode = kwargs.get('predict_mode', False)\n",
    "        feed_recurrence = params.get('feed_recurrence', 0)\n",
    "        \n",
    "        Ds = Xs['diaact']\n",
    "        Ws = Xs['words']\n",
    "        \n",
    "        # diaact input layer to hidden layer\n",
    "        Wah = self.model['Wah']\n",
    "        bah = self.model['bah']\n",
    "        Dsh = Ds.dot(Wah) + bah\n",
    "        \n",
    "        WLSTM = self.model['WLSTM']\n",
    "        n, xd = Ws.shape\n",
    "        \n",
    "        d = self.model['Wd'].shape[0] # size of hidden layer\n",
    "        Hin = np.zeros((n, WLSTM.shape[0])) # xt, ht-1, bias\n",
    "        Hout = np.zeros((n, d))\n",
    "        IFOG = np.zeros((n, 4*d))\n",
    "        IFOGf = np.zeros((n, 4*d)) # after nonlinearity\n",
    "        Cellin = np.zeros((n, d))\n",
    "        Cellout = np.zeros((n, d))\n",
    "    \n",
    "        for t in xrange(n):\n",
    "            prev = np.zeros(d) if t==0 else Hout[t-1]\n",
    "            Hin[t,0] = 1 # bias\n",
    "            Hin[t, 1:1+xd] = Ws[t]\n",
    "            Hin[t, 1+xd:] = prev\n",
    "            \n",
    "            # compute all gate activations. dots:\n",
    "            IFOG[t] = Hin[t].dot(WLSTM)\n",
    "            \n",
    "            # add diaact vector here\n",
    "            if feed_recurrence == 0:\n",
    "                if t == 0: IFOG[t] += Dsh[0]\n",
    "            else:\n",
    "                IFOG[t] += Dsh[0]\n",
    "\n",
    "            IFOGf[t, :3*d] = 1/(1+np.exp(-IFOG[t, :3*d])) # sigmoids; these are three gates\n",
    "            IFOGf[t, 3*d:] = np.tanh(IFOG[t, 3*d:]) # tanh for input value\n",
    "            \n",
    "            Cellin[t] = IFOGf[t, :d] * IFOGf[t, 3*d:]\n",
    "            if t>0: Cellin[t] += IFOGf[t, d:2*d]*Cellin[t-1]\n",
    "            \n",
    "            Cellout[t] = np.tanh(Cellin[t])\n",
    "            \n",
    "            Hout[t] = IFOGf[t, 2*d:3*d] * Cellout[t]\n",
    "\n",
    "        Wd = self.model['Wd']\n",
    "        bd = self.model['bd']\n",
    "            \n",
    "        Y = Hout.dot(Wd)+bd\n",
    "            \n",
    "        cache = {}\n",
    "        if not predict_mode:\n",
    "            cache['WLSTM'] = WLSTM\n",
    "            cache['Hout'] = Hout\n",
    "            cache['WLSTM'] = WLSTM\n",
    "            cache['Wd'] = Wd\n",
    "            cache['IFOGf'] = IFOGf\n",
    "            cache['IFOG'] = IFOG\n",
    "            cache['Cellin'] = Cellin\n",
    "            cache['Cellout'] = Cellout\n",
    "            cache['Ws'] = Ws\n",
    "            cache['Ds'] = Ds\n",
    "            cache['Hin'] = Hin\n",
    "            cache['Dsh'] = Dsh\n",
    "            cache['Wah'] = Wah\n",
    "            cache['feed_recurrence'] = feed_recurrence\n",
    "            \n",
    "        return Y, cache\n",
    "    \n",
    "    \"\"\" Forward pass on prediction \"\"\"\n",
    "    def forward(self, dict, Xs, params, **kwargs):\n",
    "        max_len = params.get('max_len', 30)\n",
    "        feed_recurrence = params.get('feed_recurrence', 0)\n",
    "        decoder_sampling = params.get('decoder_sampling', 0)\n",
    "        \n",
    "        Ds = Xs['diaact']\n",
    "        Ws = Xs['words']\n",
    "        \n",
    "        # diaact input layer to hidden layer\n",
    "        Wah = self.model['Wah']\n",
    "        bah = self.model['bah']\n",
    "        Dsh = Ds.dot(Wah) + bah\n",
    "        \n",
    "        WLSTM = self.model['WLSTM']\n",
    "        xd = Ws.shape[1]\n",
    "        \n",
    "        d = self.model['Wd'].shape[0] # size of hidden layer\n",
    "        Hin = np.zeros((1, WLSTM.shape[0])) # xt, ht-1, bias\n",
    "        Hout = np.zeros((1, d))\n",
    "        IFOG = np.zeros((1, 4*d))\n",
    "        IFOGf = np.zeros((1, 4*d)) # after nonlinearity\n",
    "        Cellin = np.zeros((1, d))\n",
    "        Cellout = np.zeros((1, d))\n",
    "        \n",
    "        Wd = self.model['Wd']\n",
    "        bd = self.model['bd']\n",
    "        \n",
    "        Hin[0,0] = 1 # bias\n",
    "        Hin[0,1:1+xd] = Ws[0]\n",
    "        \n",
    "        IFOG[0] = Hin[0].dot(WLSTM)\n",
    "        IFOG[0] += Dsh[0]\n",
    "        \n",
    "        IFOGf[0, :3*d] = 1/(1+np.exp(-IFOG[0, :3*d])) # sigmoids; these are three gates\n",
    "        IFOGf[0, 3*d:] = np.tanh(IFOG[0, 3*d:]) # tanh for input value\n",
    "            \n",
    "        Cellin[0] = IFOGf[0, :d] * IFOGf[0, 3*d:]\n",
    "        Cellout[0] = np.tanh(Cellin[0])\n",
    "        Hout[0] = IFOGf[0, 2*d:3*d] * Cellout[0]\n",
    "        \n",
    "        pred_y = []\n",
    "        pred_words = []\n",
    "        \n",
    "        Y = Hout.dot(Wd) + bd\n",
    "        maxes = np.amax(Y, axis=1, keepdims=True)\n",
    "        e = np.exp(Y - maxes) # for numerical stability shift into good numerical range\n",
    "        probs = e/np.sum(e, axis=1, keepdims=True)\n",
    "            \n",
    "        if decoder_sampling == 0: # sampling or argmax\n",
    "            pred_y_index = np.nanargmax(Y)\n",
    "        else:\n",
    "            pred_y_index = np.random.choice(Y.shape[1], 1, p=probs[0])[0]\n",
    "        pred_y.append(pred_y_index)\n",
    "        pred_words.append(dict[pred_y_index])\n",
    "        \n",
    "        time_stamp = 0\n",
    "        while True:\n",
    "            if dict[pred_y_index] == 'e_o_s' or time_stamp >= max_len: break\n",
    "            \n",
    "            X = np.zeros(xd)\n",
    "            X[pred_y_index] = 1\n",
    "            Hin[0,0] = 1 # bias\n",
    "            Hin[0,1:1+xd] = X\n",
    "            Hin[0, 1+xd:] = Hout[0]\n",
    "            \n",
    "            IFOG[0] = Hin[0].dot(WLSTM)\n",
    "            if feed_recurrence == 1:\n",
    "                IFOG[0] += Dsh[0]\n",
    "        \n",
    "            IFOGf[0, :3*d] = 1/(1+np.exp(-IFOG[0, :3*d])) # sigmoids; these are three gates\n",
    "            IFOGf[0, 3*d:] = np.tanh(IFOG[0, 3*d:]) # tanh for input value\n",
    "            \n",
    "            C = IFOGf[0, :d]*IFOGf[0, 3*d:]\n",
    "            Cellin[0] = C + IFOGf[0, d:2*d]*Cellin[0]\n",
    "            Cellout[0] = np.tanh(Cellin[0])\n",
    "            Hout[0] = IFOGf[0, 2*d:3*d]*Cellout[0]\n",
    "            \n",
    "            Y = Hout.dot(Wd) + bd\n",
    "            maxes = np.amax(Y, axis=1, keepdims=True)\n",
    "            e = np.exp(Y - maxes) # for numerical stability shift into good numerical range\n",
    "            probs = e/np.sum(e, axis=1, keepdims=True)\n",
    "            \n",
    "            if decoder_sampling == 0:\n",
    "                pred_y_index = np.nanargmax(Y)\n",
    "            else:\n",
    "                pred_y_index = np.random.choice(Y.shape[1], 1, p=probs[0])[0]\n",
    "            pred_y.append(pred_y_index)\n",
    "            pred_words.append(dict[pred_y_index])\n",
    "            \n",
    "            time_stamp += 1\n",
    "            \n",
    "        return pred_y, pred_words\n",
    "    \n",
    "    \"\"\" Forward pass on prediction with Beam Search \"\"\"\n",
    "    def beam_forward(self, dict, Xs, params, **kwargs):\n",
    "        max_len = params.get('max_len', 30)\n",
    "        feed_recurrence = params.get('feed_recurrence', 0)\n",
    "        beam_size = params.get('beam_size', 10)\n",
    "        decoder_sampling = params.get('decoder_sampling', 0)\n",
    "        \n",
    "        Ds = Xs['diaact']\n",
    "        Ws = Xs['words']\n",
    "        \n",
    "        # diaact input layer to hidden layer\n",
    "        Wah = self.model['Wah']\n",
    "        bah = self.model['bah']\n",
    "        Dsh = Ds.dot(Wah) + bah\n",
    "        \n",
    "        WLSTM = self.model['WLSTM']\n",
    "        xd = Ws.shape[1]\n",
    "        \n",
    "        d = self.model['Wd'].shape[0] # size of hidden layer\n",
    "        Hin = np.zeros((1, WLSTM.shape[0])) # xt, ht-1, bias\n",
    "        Hout = np.zeros((1, d))\n",
    "        IFOG = np.zeros((1, 4*d))\n",
    "        IFOGf = np.zeros((1, 4*d)) # after nonlinearity\n",
    "        Cellin = np.zeros((1, d))\n",
    "        Cellout = np.zeros((1, d))\n",
    "        \n",
    "        Wd = self.model['Wd']\n",
    "        bd = self.model['bd']\n",
    "        \n",
    "        Hin[0,0] = 1 # bias\n",
    "        Hin[0,1:1+xd] = Ws[0]\n",
    "        \n",
    "        IFOG[0] = Hin[0].dot(WLSTM)\n",
    "        IFOG[0] += Dsh[0]\n",
    "        \n",
    "        IFOGf[0, :3*d] = 1/(1+np.exp(-IFOG[0, :3*d])) # sigmoids; these are three gates\n",
    "        IFOGf[0, 3*d:] = np.tanh(IFOG[0, 3*d:]) # tanh for input value\n",
    "            \n",
    "        Cellin[0] = IFOGf[0, :d] * IFOGf[0, 3*d:]\n",
    "        Cellout[0] = np.tanh(Cellin[0])\n",
    "        Hout[0] = IFOGf[0, 2*d:3*d] * Cellout[0]\n",
    "        \n",
    "        # keep a beam here\n",
    "        beams = [] \n",
    "        \n",
    "        Y = Hout.dot(Wd) + bd\n",
    "        maxes = np.amax(Y, axis=1, keepdims=True)\n",
    "        e = np.exp(Y - maxes) # for numerical stability shift into good numerical range\n",
    "        probs = e/np.sum(e, axis=1, keepdims=True)\n",
    "        \n",
    "        # add beam search here\n",
    "        if decoder_sampling == 0: # no sampling\n",
    "            beam_candidate_t = (-probs[0]).argsort()[:beam_size]\n",
    "        else:\n",
    "            beam_candidate_t = np.random.choice(Y.shape[1], beam_size, p=probs[0])\n",
    "        #beam_candidate_t = (-probs[0]).argsort()[:beam_size]\n",
    "        for ele in beam_candidate_t:\n",
    "            beams.append((np.log(probs[0][ele]), [ele], [dict[ele]], Hout[0], Cellin[0]))\n",
    "        \n",
    "        #beams.sort(key=lambda x:x[0], reverse=True)\n",
    "        #beams.sort(reverse = True)\n",
    "        \n",
    "        time_stamp = 0\n",
    "        while True:\n",
    "            beam_candidates = []\n",
    "            for b in beams:\n",
    "                log_prob = b[0]\n",
    "                pred_y_index = b[1][-1]\n",
    "                cell_in = b[4]\n",
    "                hout_prev = b[3]\n",
    "                \n",
    "                if b[2][-1] == \"e_o_s\": # this beam predicted end token. Keep in the candidates but don't expand it out any more\n",
    "                    beam_candidates.append(b)\n",
    "                    continue\n",
    "        \n",
    "                X = np.zeros(xd)\n",
    "                X[pred_y_index] = 1\n",
    "                Hin[0,0] = 1 # bias\n",
    "                Hin[0,1:1+xd] = X\n",
    "                Hin[0, 1+xd:] = hout_prev\n",
    "                \n",
    "                IFOG[0] = Hin[0].dot(WLSTM)\n",
    "                if feed_recurrence == 1: IFOG[0] += Dsh[0]\n",
    "        \n",
    "                IFOGf[0, :3*d] = 1/(1+np.exp(-IFOG[0, :3*d])) # sigmoids; these are three gates\n",
    "                IFOGf[0, 3*d:] = np.tanh(IFOG[0, 3*d:]) # tanh for input value\n",
    "            \n",
    "                C = IFOGf[0, :d]*IFOGf[0, 3*d:]\n",
    "                cell_in = C + IFOGf[0, d:2*d]*cell_in\n",
    "                cell_out = np.tanh(cell_in)\n",
    "                hout_prev = IFOGf[0, 2*d:3*d]*cell_out\n",
    "                \n",
    "                Y = hout_prev.dot(Wd) + bd\n",
    "                maxes = np.amax(Y, axis=1, keepdims=True)\n",
    "                e = np.exp(Y - maxes) # for numerical stability shift into good numerical range\n",
    "                probs = e/np.sum(e, axis=1, keepdims=True)\n",
    "                \n",
    "                if decoder_sampling == 0: # no sampling\n",
    "                    beam_candidate_t = (-probs[0]).argsort()[:beam_size]\n",
    "                else:\n",
    "                    beam_candidate_t = np.random.choice(Y.shape[1], beam_size, p=probs[0])\n",
    "                #beam_candidate_t = (-probs[0]).argsort()[:beam_size]\n",
    "                for ele in beam_candidate_t:\n",
    "                    beam_candidates.append((log_prob+np.log(probs[0][ele]), np.append(b[1], ele), np.append(b[2], dict[ele]), hout_prev, cell_in))\n",
    "            \n",
    "            beam_candidates.sort(key=lambda x:x[0], reverse=True)\n",
    "            #beam_candidates.sort(reverse = True) # decreasing order\n",
    "            beams = beam_candidates[:beam_size]\n",
    "            time_stamp += 1\n",
    "\n",
    "            if time_stamp >= max_len: break\n",
    "        \n",
    "        return beams[0][1], beams[0][2]\n",
    "    \n",
    "    \"\"\" Backward Pass \"\"\"\n",
    "    def bwdPass(self, dY, cache):\n",
    "        Wd = cache['Wd']\n",
    "        Hout = cache['Hout']\n",
    "        IFOG = cache['IFOG']\n",
    "        IFOGf = cache['IFOGf']\n",
    "        Cellin = cache['Cellin']\n",
    "        Cellout = cache['Cellout']\n",
    "        Hin = cache['Hin']\n",
    "        WLSTM = cache['WLSTM']\n",
    "        Ws = cache['Ws']\n",
    "        Ds = cache['Ds']\n",
    "        Dsh = cache['Dsh']\n",
    "        Wah = cache['Wah']\n",
    "        feed_recurrence = cache['feed_recurrence']\n",
    "        \n",
    "        n,d = Hout.shape\n",
    "\n",
    "        # backprop the hidden-output layer\n",
    "        dWd = Hout.transpose().dot(dY)\n",
    "        dbd = np.sum(dY, axis=0, keepdims = True)\n",
    "        dHout = dY.dot(Wd.transpose())\n",
    "\n",
    "        # backprop the LSTM\n",
    "        dIFOG = np.zeros(IFOG.shape)\n",
    "        dIFOGf = np.zeros(IFOGf.shape)\n",
    "        dWLSTM = np.zeros(WLSTM.shape)\n",
    "        dHin = np.zeros(Hin.shape)\n",
    "        dCellin = np.zeros(Cellin.shape)\n",
    "        dCellout = np.zeros(Cellout.shape)\n",
    "        dWs = np.zeros(Ws.shape)\n",
    "        \n",
    "        dDsh = np.zeros(Dsh.shape)\n",
    "        \n",
    "        for t in reversed(xrange(n)):\n",
    "            dIFOGf[t,2*d:3*d] = Cellout[t] * dHout[t]\n",
    "            dCellout[t] = IFOGf[t,2*d:3*d] * dHout[t]\n",
    "            \n",
    "            dCellin[t] += (1-Cellout[t]**2) * dCellout[t]\n",
    "            \n",
    "            if t>0:\n",
    "                dIFOGf[t, d:2*d] = Cellin[t-1] * dCellin[t]\n",
    "                dCellin[t-1] += IFOGf[t,d:2*d] * dCellin[t]\n",
    "            \n",
    "            dIFOGf[t, :d] = IFOGf[t,3*d:] * dCellin[t]\n",
    "            dIFOGf[t,3*d:] = IFOGf[t, :d] * dCellin[t]\n",
    "            \n",
    "            # backprop activation functions\n",
    "            dIFOG[t, 3*d:] = (1-IFOGf[t, 3*d:]**2) * dIFOGf[t, 3*d:]\n",
    "            y = IFOGf[t, :3*d]\n",
    "            dIFOG[t, :3*d] = (y*(1-y)) * dIFOGf[t, :3*d]\n",
    "            \n",
    "            # backprop matrix multiply\n",
    "            dWLSTM += np.outer(Hin[t], dIFOG[t])\n",
    "            dHin[t] = dIFOG[t].dot(WLSTM.transpose())\n",
    "      \n",
    "            if t > 0: dHout[t-1] += dHin[t,1+Ws.shape[1]:]\n",
    "            \n",
    "            if feed_recurrence == 0:\n",
    "                if t == 0: dDsh[t] = dIFOG[t]\n",
    "            else: \n",
    "                dDsh[0] += dIFOG[t]\n",
    "        \n",
    "        # backprop to the diaact-hidden connections\n",
    "        dWah = Ds.transpose().dot(dDsh)\n",
    "        dbah = np.sum(dDsh, axis=0, keepdims = True)\n",
    "             \n",
    "        return {'Wah':dWah, 'bah':dbah, 'WLSTM':dWLSTM, 'Wd':dWd, 'bd':dbd}\n",
    "    \n",
    "    \n",
    "    \"\"\" Batch data representation \"\"\"\n",
    "    def prepare_input_rep(self, ds, batch, params):\n",
    "        batch_reps = []\n",
    "        for i,x in enumerate(batch):\n",
    "            batch_rep = {}\n",
    "            \n",
    "            vec = np.zeros((1, self.model['Wah'].shape[0]))\n",
    "            vec[0][x['diaact_rep']] = 1\n",
    "            for v in x['slotrep']:\n",
    "                vec[0][v] = 1\n",
    "            \n",
    "            word_arr = x['sentence'].split(' ')\n",
    "            word_vecs = np.zeros((len(word_arr), self.model['Wxh'].shape[0]))\n",
    "            labels = [0] * (len(word_arr)-1)\n",
    "            for w_index, w in enumerate(word_arr[:-1]):\n",
    "                if w in ds.data['word_dict'].keys():\n",
    "                    w_dict_index = ds.data['word_dict'][w]\n",
    "                    word_vecs[w_index][w_dict_index] = 1\n",
    "                \n",
    "                if word_arr[w_index+1] in ds.data['word_dict'].keys():\n",
    "                    labels[w_index] = ds.data['word_dict'][word_arr[w_index+1]] \n",
    "            \n",
    "            batch_rep['diaact'] = vec\n",
    "            batch_rep['words'] = word_vecs\n",
    "            batch_rep['labels'] = labels\n",
    "            batch_reps.append(batch_rep)\n",
    "        return batch_reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nlg:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def post_process(self, pred_template, slot_val_dict, slot_dict):\n",
    "        \"\"\" post_process to fill the slot in the template sentence \"\"\"\n",
    "        \n",
    "        sentence = pred_template\n",
    "        suffix = \"_PLACEHOLDER\"\n",
    "        \n",
    "        for slot in slot_val_dict.keys():\n",
    "            slot_vals = slot_val_dict[slot]\n",
    "            slot_placeholder = slot + suffix\n",
    "            if slot == 'result' or slot == 'numberofpeople': continue\n",
    "            if slot_vals == NO_VALUE_MATCH: continue\n",
    "            tmp_sentence = sentence.replace(slot_placeholder, slot_vals, 1)\n",
    "            sentence = tmp_sentence\n",
    "                \n",
    "        if 'numberofpeople' in slot_val_dict.keys():\n",
    "            slot_vals = slot_val_dict['numberofpeople']\n",
    "            slot_placeholder = 'numberofpeople' + suffix\n",
    "            tmp_sentence = sentence.replace(slot_placeholder, slot_vals, 1)\n",
    "            sentence = tmp_sentence\n",
    "    \n",
    "        for slot in slot_dict.keys():\n",
    "            slot_placeholder = slot + suffix\n",
    "            tmp_sentence = sentence.replace(slot_placeholder, '')\n",
    "            sentence = tmp_sentence\n",
    "            \n",
    "        return sentence\n",
    "\n",
    "    \n",
    "    def convert_diaact_to_nl(self, dia_act, turn_msg):\n",
    "        \"\"\" Convert Dia_Act into NL: Rule + Model \"\"\"\n",
    "        \n",
    "        sentence = \"\"\n",
    "        boolean_in = False\n",
    "        \n",
    "        # remove I do not care slot in task(complete)\n",
    "        if dia_act['diaact'] == 'inform' and 'taskcomplete' in dia_act['inform_slots'].keys() and dia_act['inform_slots']['taskcomplete'] != NO_VALUE_MATCH:\n",
    "            inform_slot_set = dia_act['inform_slots'].keys()\n",
    "            for slot in inform_slot_set:\n",
    "                if dia_act['inform_slots'][slot] == I_DO_NOT_CARE: del dia_act['inform_slots'][slot]\n",
    "        \n",
    "        if dia_act['diaact'] in self.diaact_nl_pairs['dia_acts'].keys():\n",
    "            for ele in self.diaact_nl_pairs['dia_acts'][dia_act['diaact']]:\n",
    "                if set(ele['inform_slots']) == set(dia_act['inform_slots'].keys()) and set(ele['request_slots']) == set(dia_act['request_slots'].keys()):\n",
    "                    sentence = self.diaact_to_nl_slot_filling(dia_act, ele['nl'][turn_msg])\n",
    "                    boolean_in = True\n",
    "                    break\n",
    "        \n",
    "        if dia_act['diaact'] == 'inform' and 'taskcomplete' in dia_act['inform_slots'].keys() and dia_act['inform_slots']['taskcomplete'] == NO_VALUE_MATCH:\n",
    "            sentence = \"Oh sorry, there is no ticket available.\"\n",
    "        \n",
    "        if boolean_in == False: sentence = self.translate_diaact(dia_act)\n",
    "        return sentence\n",
    "        \n",
    "        \n",
    "    def translate_diaact(self, dia_act):\n",
    "        \"\"\" prepare the diaact into vector representation, and generate the sentence by Model \"\"\"\n",
    "        \n",
    "        word_dict = self.word_dict\n",
    "        template_word_dict = self.template_word_dict\n",
    "        act_dict = self.act_dict\n",
    "        slot_dict = self.slot_dict\n",
    "        inverse_word_dict = self.inverse_word_dict\n",
    "    \n",
    "        act_rep = np.zeros((1, len(act_dict)))\n",
    "        act_rep[0, act_dict[dia_act['diaact']]] = 1.0\n",
    "    \n",
    "        slot_rep_bit = 2\n",
    "        slot_rep = np.zeros((1, len(slot_dict)*slot_rep_bit)) \n",
    "    \n",
    "        suffix = \"_PLACEHOLDER\"\n",
    "        if self.params['dia_slot_val'] == 2 or self.params['dia_slot_val'] == 3:\n",
    "            word_rep = np.zeros((1, len(template_word_dict)))\n",
    "            words = np.zeros((1, len(template_word_dict)))\n",
    "            words[0, template_word_dict['s_o_s']] = 1.0\n",
    "        else:\n",
    "            word_rep = np.zeros((1, len(word_dict)))\n",
    "            words = np.zeros((1, len(word_dict)))\n",
    "            words[0, word_dict['s_o_s']] = 1.0\n",
    "    \n",
    "        for slot in dia_act['inform_slots'].keys():\n",
    "            slot_index = slot_dict[slot]\n",
    "            slot_rep[0, slot_index*slot_rep_bit] = 1.0\n",
    "        \n",
    "            for slot_val in dia_act['inform_slots'][slot]:\n",
    "                if self.params['dia_slot_val'] == 2:\n",
    "                    slot_placeholder = slot + suffix\n",
    "                    if slot_placeholder in template_word_dict.keys():\n",
    "                        word_rep[0, template_word_dict[slot_placeholder]] = 1.0\n",
    "                elif self.params['dia_slot_val'] == 1:\n",
    "                    if slot_val in word_dict.keys():\n",
    "                        word_rep[0, word_dict[slot_val]] = 1.0\n",
    "                    \n",
    "        for slot in dia_act['request_slots'].keys():\n",
    "            slot_index = slot_dict[slot]\n",
    "            slot_rep[0, slot_index*slot_rep_bit + 1] = 1.0\n",
    "    \n",
    "        if self.params['dia_slot_val'] == 0 or self.params['dia_slot_val'] == 3:\n",
    "            final_representation = np.hstack([act_rep, slot_rep])\n",
    "        else: # dia_slot_val = 1, 2\n",
    "            final_representation = np.hstack([act_rep, slot_rep, word_rep])\n",
    "    \n",
    "        dia_act_rep = {}\n",
    "        dia_act_rep['diaact'] = final_representation\n",
    "        dia_act_rep['words'] = words\n",
    "    \n",
    "        #pred_ys, pred_words = nlg_model['model'].forward(inverse_word_dict, dia_act_rep, nlg_model['params'], predict_model=True)\n",
    "        pred_ys, pred_words = self.model.beam_forward(inverse_word_dict, dia_act_rep, self.params, predict_model=True)\n",
    "        pred_sentence = ' '.join(pred_words[:-1])\n",
    "        sentence = self.post_process(pred_sentence, dia_act['inform_slots'], slot_dict)\n",
    "            \n",
    "        return sentence\n",
    "    \n",
    "    \n",
    "    def load_nlg_model(self, model_path):\n",
    "        \"\"\" load the trained NLG model \"\"\"  \n",
    "        \n",
    "        model_params = pickle.load(open(model_path, 'rb'))\n",
    "    \n",
    "        hidden_size = model_params['model']['Wd'].shape[0]\n",
    "        output_size = model_params['model']['Wd'].shape[1]\n",
    "    \n",
    "        if model_params['params']['model'] == 'lstm_tanh': # lstm_tanh\n",
    "            diaact_input_size = model_params['model']['Wah'].shape[0]\n",
    "            input_size = model_params['model']['WLSTM'].shape[0] - hidden_size - 1\n",
    "            rnnmodel = lstm_decoder_tanh(diaact_input_size, input_size, hidden_size, output_size)\n",
    "        \n",
    "        rnnmodel.model = copy.deepcopy(model_params['model'])\n",
    "        model_params['params']['beam_size'] = nlg_beam_size\n",
    "        \n",
    "        self.model = rnnmodel\n",
    "        self.word_dict = copy.deepcopy(model_params['word_dict'])\n",
    "        self.template_word_dict = copy.deepcopy(model_params['template_word_dict'])\n",
    "        self.slot_dict = copy.deepcopy(model_params['slot_dict'])\n",
    "        self.act_dict = copy.deepcopy(model_params['act_dict'])\n",
    "        self.inverse_word_dict = {self.template_word_dict[k]:k for k in self.template_word_dict.keys()}\n",
    "        self.params = copy.deepcopy(model_params['params'])\n",
    "        \n",
    "    \n",
    "    def diaact_to_nl_slot_filling(self, dia_act, template_sentence):\n",
    "        \"\"\" Replace the slots with its values \"\"\"\n",
    "        \n",
    "        sentence = template_sentence\n",
    "        counter = 0\n",
    "        for slot in dia_act['inform_slots'].keys():\n",
    "            slot_val = dia_act['inform_slots'][slot]\n",
    "            if slot_val == NO_VALUE_MATCH:\n",
    "                sentence = slot + \" is not available!\"\n",
    "                break\n",
    "            elif slot_val == I_DO_NOT_CARE:\n",
    "                counter += 1\n",
    "                sentence = sentence.replace('$'+slot+'$', '', 1)\n",
    "                continue\n",
    "            \n",
    "            sentence = sentence.replace('$'+slot+'$', slot_val, 1)\n",
    "        \n",
    "        if counter > 0 and counter == len(dia_act['inform_slots']):\n",
    "            sentence = I_DO_NOT_CARE\n",
    "        \n",
    "        return sentence\n",
    "    \n",
    "    \n",
    "    def load_predefine_act_nl_pairs(self, path):\n",
    "        \"\"\" Load some pre-defined Dia_Act&NL Pairs from file \"\"\"\n",
    "        \n",
    "        self.diaact_nl_pairs = json.load(open(path, 'rb'))\n",
    "        \n",
    "        for key in self.diaact_nl_pairs['dia_acts'].keys():\n",
    "            for ele in self.diaact_nl_pairs['dia_acts'][key]:\n",
    "                ele['nl']['usr'] = ele['nl']['usr'].encode('utf-8') # encode issue\n",
    "                ele['nl']['agt'] = ele['nl']['agt'].encode('utf-8') # encode issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqToSeq:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        pass\n",
    "    \n",
    "    def get_struct(self):\n",
    "        return {'model': self.model, 'update': self.update, 'regularize': self.regularize}\n",
    "    \n",
    "    \n",
    "    \"\"\" Forward Function\"\"\"\n",
    "    def fwdPass(self, Xs, params, **kwargs):\n",
    "        pass\n",
    "    \n",
    "    def bwdPass(self, dY, cache):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \"\"\" Batch Forward & Backward Pass\"\"\"\n",
    "    def batchForward(self, ds, batch, params, predict_mode = False):\n",
    "        caches = []\n",
    "        Ys = []\n",
    "        for i,x in enumerate(batch):\n",
    "            Y, out_cache = self.fwdPass(x, params, predict_mode = predict_mode)\n",
    "            caches.append(out_cache)\n",
    "            Ys.append(Y)\n",
    "           \n",
    "        # back up information for efficient backprop\n",
    "        cache = {}\n",
    "        if not predict_mode:\n",
    "            cache['caches'] = caches\n",
    "\n",
    "        return Ys, cache\n",
    "    \n",
    "    def batchBackward(self, dY, cache):\n",
    "        caches = cache['caches']\n",
    "        grads = {}\n",
    "        for i in xrange(len(caches)):\n",
    "            single_cache = caches[i]\n",
    "            local_grads = self.bwdPass(dY[i], single_cache)\n",
    "            mergeDicts(grads, local_grads) # add up the gradients wrt model parameters\n",
    "            \n",
    "        return grads\n",
    "\n",
    "\n",
    "    \"\"\" Cost function, returns cost and gradients for model \"\"\"\n",
    "    def costFunc(self, ds, batch, params):\n",
    "        regc = params['reg_cost'] # regularization cost\n",
    "        \n",
    "        # batch forward RNN\n",
    "        Ys, caches = self.batchForward(ds, batch, params, predict_mode = False)\n",
    "        \n",
    "        loss_cost = 0.0\n",
    "        smooth_cost = 1e-15\n",
    "        dYs = []\n",
    "        \n",
    "        for i,x in enumerate(batch):\n",
    "            labels = np.array(x['tags_rep'], dtype=int)\n",
    "            \n",
    "            # fetch the predicted probabilities\n",
    "            Y = Ys[i]\n",
    "            maxes = np.amax(Y, axis=1, keepdims=True)\n",
    "            e = np.exp(Y - maxes) # for numerical stability shift into good numerical range\n",
    "            P = e/np.sum(e, axis=1, keepdims=True)\n",
    "            \n",
    "            # Cross-Entropy Cross Function\n",
    "            loss_cost += -np.sum(np.log(smooth_cost + P[range(len(labels)), labels]))\n",
    "            \n",
    "            for iy,y in enumerate(labels):\n",
    "                P[iy,y] -= 1 # softmax derivatives\n",
    "            dYs.append(P)\n",
    "            \n",
    "        # backprop the RNN\n",
    "        grads = self.batchBackward(dYs, caches)\n",
    "        \n",
    "        # add L2 regularization cost and gradients\n",
    "        reg_cost = 0.0\n",
    "        if regc > 0:    \n",
    "            for p in self.regularize:\n",
    "                mat = self.model[p]\n",
    "                reg_cost += 0.5*regc*np.sum(mat*mat)\n",
    "                grads[p] += regc*mat\n",
    "\n",
    "        # normalize the cost and gradient by the batch size\n",
    "        batch_size = len(batch)\n",
    "        reg_cost /= batch_size\n",
    "        loss_cost /= batch_size\n",
    "        for k in grads: grads[k] /= batch_size\n",
    "\n",
    "        out = {}\n",
    "        out['cost'] = {'reg_cost' : reg_cost, 'loss_cost' : loss_cost, 'total_cost' : loss_cost + reg_cost}\n",
    "        out['grads'] = grads\n",
    "        return out\n",
    "\n",
    "\n",
    "    \"\"\" A single batch \"\"\"\n",
    "    def singleBatch(self, ds, batch, params):\n",
    "        learning_rate = params.get('learning_rate', 0.0)\n",
    "        decay_rate = params.get('decay_rate', 0.999)\n",
    "        momentum = params.get('momentum', 0)\n",
    "        grad_clip = params.get('grad_clip', 1)\n",
    "        smooth_eps = params.get('smooth_eps', 1e-8)\n",
    "        sdg_type = params.get('sdgtype', 'rmsprop')\n",
    "\n",
    "        for u in self.update:\n",
    "            if not u in self.step_cache: \n",
    "                self.step_cache[u] = np.zeros(self.model[u].shape)\n",
    "        \n",
    "        cg = self.costFunc(ds, batch, params)\n",
    "        \n",
    "        cost = cg['cost']\n",
    "        grads = cg['grads']\n",
    "        \n",
    "        # clip gradients if needed\n",
    "        if params['activation_func'] == 'relu':\n",
    "            if grad_clip > 0:\n",
    "                for p in self.update:\n",
    "                    if p in grads:\n",
    "                        grads[p] = np.minimum(grads[p], grad_clip)\n",
    "                        grads[p] = np.maximum(grads[p], -grad_clip)\n",
    "        \n",
    "        # perform parameter update\n",
    "        for p in self.update:\n",
    "            if p in grads:\n",
    "                if sdg_type == 'vanilla':\n",
    "                    if momentum > 0: dx = momentum*self.step_cache[p] - learning_rate*grads[p]\n",
    "                    else: dx = -learning_rate*grads[p]\n",
    "                    self.step_cache[p] = dx\n",
    "                elif sdg_type == 'rmsprop':\n",
    "                    self.step_cache[p] = self.step_cache[p]*decay_rate + (1.0-decay_rate)*grads[p]**2\n",
    "                    dx = -(learning_rate*grads[p])/np.sqrt(self.step_cache[p] + smooth_eps)\n",
    "                elif sdg_type == 'adgrad':\n",
    "                    self.step_cache[p] += grads[p]**2\n",
    "                    dx = -(learning_rate*grads[p])/np.sqrt(self.step_cache[p] + smooth_eps)\n",
    "                    \n",
    "                self.model[p] += dx\n",
    "\n",
    "        # create output dict and return\n",
    "        out = {}\n",
    "        out['cost'] = cost\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    \"\"\" Evaluate on the dataset[split] \"\"\"\n",
    "    def eval(self, ds, split, params):\n",
    "        acc = 0\n",
    "        total = 0\n",
    "        \n",
    "        total_cost = 0.0\n",
    "        smooth_cost = 1e-15\n",
    "        \n",
    "        if split == 'test':\n",
    "            res_filename = 'res_%s_[%s].txt' % (params['model'], time.time())\n",
    "            res_filepath = os.path.join(params['test_res_dir'], res_filename)\n",
    "            res = open(res_filepath, 'w')\n",
    "            inverse_tag_dict = {ds.data['tag_set'][k]:k for k in ds.data['tag_set'].keys()}\n",
    "            \n",
    "        for i, ele in enumerate(ds.split[split]):\n",
    "            Ys, cache = self.fwdPass(ele, params, predict_model=True)\n",
    "            \n",
    "            maxes = np.amax(Ys, axis=1, keepdims=True)\n",
    "            e = np.exp(Ys - maxes) # for numerical stability shift into good numerical range\n",
    "            probs = e/np.sum(e, axis=1, keepdims=True)\n",
    "            \n",
    "            labels = np.array(ele['tags_rep'], dtype=int)\n",
    "            \n",
    "            if np.all(np.isnan(probs)): probs = np.zeros(probs.shape)\n",
    "            \n",
    "            loss_cost = 0\n",
    "            loss_cost += -np.sum(np.log(smooth_cost + probs[range(len(labels)), labels]))\n",
    "            total_cost += loss_cost\n",
    "            \n",
    "            pred_words_indices = np.nanargmax(probs, axis=1)\n",
    "            \n",
    "            tokens = ele['raw_seq']\n",
    "            real_tags = ele['tag_seq']\n",
    "            for index, l in enumerate(labels):\n",
    "                if pred_words_indices[index] == l: acc += 1\n",
    "                \n",
    "                if split == 'test':\n",
    "                    res.write('%s %s %s %s\\n' % (tokens[index], 'NA', real_tags[index], inverse_tag_dict[pred_words_indices[index]]))\n",
    "            if split == 'test': res.write('\\n')\n",
    "            total += len(labels)\n",
    "            \n",
    "        total_cost /= len(ds.split[split])\n",
    "        accuracy = 0 if total == 0 else float(acc)/total\n",
    "        \n",
    "        #print (\"total_cost: %s, accuracy: %s\" % (total_cost, accuracy))\n",
    "        result = {'cost': total_cost, 'accuracy': accuracy}\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm(SeqToSeq):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.model = {}\n",
    "        # Recurrent weights: take x_t, h_{t-1}, and bias unit, and produce the 3 gates and the input to cell signal\n",
    "        self.model['WLSTM'] = initWeights(input_size + hidden_size + 1, 4*hidden_size)\n",
    "        # Hidden-Output Connections\n",
    "        self.model['Wd'] = initWeights(hidden_size, output_size)*0.1\n",
    "        self.model['bd'] = np.zeros((1, output_size))\n",
    "\n",
    "        self.update = ['WLSTM', 'Wd', 'bd']\n",
    "        self.regularize = ['WLSTM', 'Wd']\n",
    "\n",
    "        self.step_cache = {}\n",
    "        \n",
    "    \"\"\" Activation Function: Sigmoid, or tanh, or ReLu \"\"\"\n",
    "    def fwdPass(self, Xs, params, **kwargs):\n",
    "        predict_mode = kwargs.get('predict_mode', False)\n",
    "        \n",
    "        Ws = Xs['word_vectors']\n",
    "        \n",
    "        WLSTM = self.model['WLSTM']\n",
    "        n, xd = Ws.shape\n",
    "        \n",
    "        d = self.model['Wd'].shape[0] # size of hidden layer\n",
    "        Hin = np.zeros((n, WLSTM.shape[0])) # xt, ht-1, bias\n",
    "        Hout = np.zeros((n, d))\n",
    "        IFOG = np.zeros((n, 4*d))\n",
    "        IFOGf = np.zeros((n, 4*d)) # after nonlinearity\n",
    "        Cellin = np.zeros((n, d))\n",
    "        Cellout = np.zeros((n, d))\n",
    "    \n",
    "        for t in xrange(n):\n",
    "            prev = np.zeros(d) if t==0 else Hout[t-1]\n",
    "            Hin[t,0] = 1 # bias\n",
    "            Hin[t, 1:1+xd] = Ws[t]\n",
    "            Hin[t, 1+xd:] = prev\n",
    "            \n",
    "            # compute all gate activations. dots:\n",
    "            IFOG[t] = Hin[t].dot(WLSTM)\n",
    "            \n",
    "            IFOGf[t, :3*d] = 1/(1+np.exp(-IFOG[t, :3*d])) # sigmoids; these are three gates\n",
    "            IFOGf[t, 3*d:] = np.tanh(IFOG[t, 3*d:]) # tanh for input value\n",
    "            \n",
    "            Cellin[t] = IFOGf[t, :d] * IFOGf[t, 3*d:]\n",
    "            if t>0: Cellin[t] += IFOGf[t, d:2*d]*Cellin[t-1]\n",
    "            \n",
    "            Cellout[t] = np.tanh(Cellin[t])\n",
    "            \n",
    "            Hout[t] = IFOGf[t, 2*d:3*d] * Cellout[t]\n",
    "\n",
    "        Wd = self.model['Wd']\n",
    "        bd = self.model['bd']\n",
    "            \n",
    "        Y = Hout.dot(Wd)+bd\n",
    "            \n",
    "        cache = {}\n",
    "        if not predict_mode:\n",
    "            cache['WLSTM'] = WLSTM\n",
    "            cache['Hout'] = Hout\n",
    "            cache['Wd'] = Wd\n",
    "            cache['IFOGf'] = IFOGf\n",
    "            cache['IFOG'] = IFOG\n",
    "            cache['Cellin'] = Cellin\n",
    "            cache['Cellout'] = Cellout\n",
    "            cache['Ws'] = Ws\n",
    "            cache['Hin'] = Hin\n",
    "            \n",
    "        return Y, cache\n",
    "    \n",
    "    \"\"\" Backward Pass \"\"\"\n",
    "    def bwdPass(self, dY, cache):\n",
    "        Wd = cache['Wd']\n",
    "        Hout = cache['Hout']\n",
    "        IFOG = cache['IFOG']\n",
    "        IFOGf = cache['IFOGf']\n",
    "        Cellin = cache['Cellin']\n",
    "        Cellout = cache['Cellout']\n",
    "        Hin = cache['Hin']\n",
    "        WLSTM = cache['WLSTM']\n",
    "        Ws = cache['Ws']\n",
    "        \n",
    "        n,d = Hout.shape\n",
    "\n",
    "        # backprop the hidden-output layer\n",
    "        dWd = Hout.transpose().dot(dY)\n",
    "        dbd = np.sum(dY, axis=0, keepdims = True)\n",
    "        dHout = dY.dot(Wd.transpose())\n",
    "\n",
    "        # backprop the LSTM\n",
    "        dIFOG = np.zeros(IFOG.shape)\n",
    "        dIFOGf = np.zeros(IFOGf.shape)\n",
    "        dWLSTM = np.zeros(WLSTM.shape)\n",
    "        dHin = np.zeros(Hin.shape)\n",
    "        dCellin = np.zeros(Cellin.shape)\n",
    "        dCellout = np.zeros(Cellout.shape)\n",
    "        \n",
    "        for t in reversed(xrange(n)):\n",
    "            dIFOGf[t,2*d:3*d] = Cellout[t] * dHout[t]\n",
    "            dCellout[t] = IFOGf[t,2*d:3*d] * dHout[t]\n",
    "            \n",
    "            dCellin[t] += (1-Cellout[t]**2) * dCellout[t]\n",
    "            \n",
    "            if t>0:\n",
    "                dIFOGf[t, d:2*d] = Cellin[t-1] * dCellin[t]\n",
    "                dCellin[t-1] += IFOGf[t,d:2*d] * dCellin[t]\n",
    "            \n",
    "            dIFOGf[t, :d] = IFOGf[t,3*d:] * dCellin[t]\n",
    "            dIFOGf[t,3*d:] = IFOGf[t, :d] * dCellin[t]\n",
    "            \n",
    "            # backprop activation functions\n",
    "            dIFOG[t, 3*d:] = (1-IFOGf[t, 3*d:]**2) * dIFOGf[t, 3*d:]\n",
    "            y = IFOGf[t, :3*d]\n",
    "            dIFOG[t, :3*d] = (y*(1-y)) * dIFOGf[t, :3*d]\n",
    "            \n",
    "            # backprop matrix multiply\n",
    "            dWLSTM += np.outer(Hin[t], dIFOG[t])\n",
    "            dHin[t] = dIFOG[t].dot(WLSTM.transpose())\n",
    "      \n",
    "            if t > 0: dHout[t-1] += dHin[t, 1+Ws.shape[1]:]\n",
    "        \n",
    "        #dXs = dXsh.dot(Wxh.transpose())  \n",
    "        return {'WLSTM':dWLSTM, 'Wd':dWd, 'bd':dbd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nlu:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def generate_dia_act(self, annot):\n",
    "        \"\"\" generate the Dia-Act with NLU model \"\"\"\n",
    "        \n",
    "        if len(annot) > 0:\n",
    "            tmp_annot = annot.strip('.').strip('?').strip(',').strip('!') \n",
    "            \n",
    "            rep = self.parse_str_to_vector(tmp_annot)\n",
    "            Ys, cache = self.model.fwdPass(rep, self.params, predict_model=True) # default: True\n",
    "            \n",
    "            maxes = np.amax(Ys, axis=1, keepdims=True)\n",
    "            e = np.exp(Ys - maxes) # for numerical stability shift into good numerical range\n",
    "            probs = e/np.sum(e, axis=1, keepdims=True)\n",
    "            if np.all(np.isnan(probs)): probs = np.zeros(probs.shape)\n",
    "            \n",
    "            # special handling with intent label\n",
    "            for tag_id in self.inverse_tag_dict.keys():\n",
    "                if self.inverse_tag_dict[tag_id].startswith('B-') or self.inverse_tag_dict[tag_id].startswith('I-') or self.inverse_tag_dict[tag_id] == 'O':\n",
    "                    probs[-1][tag_id] = 0\n",
    "            \n",
    "            pred_words_indices = np.nanargmax(probs, axis=1)\n",
    "            pred_tags = [self.inverse_tag_dict[index] for index in pred_words_indices]\n",
    "            \n",
    "            diaact = self.parse_nlu_to_diaact(pred_tags, tmp_annot)\n",
    "            return diaact\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    \n",
    "    def load_nlu_model(self, model_path):\n",
    "        \"\"\" load the trained NLU model \"\"\"  \n",
    "        \n",
    "        model_params = pickle.load(open(model_path, 'rb'))\n",
    "    \n",
    "        hidden_size = model_params['model']['Wd'].shape[0]\n",
    "        output_size = model_params['model']['Wd'].shape[1]\n",
    "    \n",
    "        if model_params['params']['model'] == 'lstm': # lstm_\n",
    "            input_size = model_params['model']['WLSTM'].shape[0] - hidden_size - 1\n",
    "            rnnmodel = lstm(input_size, hidden_size, output_size)\n",
    "        elif model_params['params']['model'] == 'bi_lstm': # bi_lstm\n",
    "            input_size = model_params['model']['WLSTM'].shape[0] - hidden_size - 1\n",
    "            rnnmodel = biLSTM(input_size, hidden_size, output_size)\n",
    "           \n",
    "        rnnmodel.model = copy.deepcopy(model_params['model'])\n",
    "        \n",
    "        self.model = rnnmodel\n",
    "        self.word_dict = copy.deepcopy(model_params['word_dict'])\n",
    "        self.slot_dict = copy.deepcopy(model_params['slot_dict'])\n",
    "        self.act_dict = copy.deepcopy(model_params['act_dict'])\n",
    "        self.tag_set = copy.deepcopy(model_params['tag_set'])\n",
    "        self.params = copy.deepcopy(model_params['params'])\n",
    "        self.inverse_tag_dict = {self.tag_set[k]:k for k in self.tag_set.keys()}\n",
    "        \n",
    "           \n",
    "    def parse_str_to_vector(self, string):\n",
    "        \"\"\" Parse string into vector representations \"\"\"\n",
    "        \n",
    "        tmp = 'BOS ' + string + ' EOS'\n",
    "        words = tmp.lower().split(' ')\n",
    "        \n",
    "        vecs = np.zeros((len(words), len(self.word_dict)))\n",
    "        for w_index, w in enumerate(words):\n",
    "            if w.endswith(',') or w.endswith('?'): w = w[0:-1]\n",
    "            if w in self.word_dict.keys():\n",
    "                vecs[w_index][self.word_dict[w]] = 1\n",
    "            else: vecs[w_index][self.word_dict['unk']] = 1\n",
    "        \n",
    "        rep = {}\n",
    "        rep['word_vectors'] = vecs\n",
    "        rep['raw_seq'] = string\n",
    "        return rep\n",
    "\n",
    "    def parse_nlu_to_diaact(self, nlu_vector, string):\n",
    "        \"\"\" Parse BIO and Intent into Dia-Act \"\"\"\n",
    "        \n",
    "        tmp = 'BOS ' + string + ' EOS'\n",
    "        words = tmp.lower().split(' ')\n",
    "    \n",
    "        diaact = {}\n",
    "        diaact['diaact'] = \"inform\"\n",
    "        diaact['request_slots'] = {}\n",
    "        diaact['inform_slots'] = {}\n",
    "        \n",
    "        intent = nlu_vector[-1]\n",
    "        index = 1\n",
    "        pre_tag = nlu_vector[0]\n",
    "        pre_tag_index = 0\n",
    "    \n",
    "        slot_val_dict = {}\n",
    "    \n",
    "        while index<(len(nlu_vector)-1): # except last Intent tag\n",
    "            cur_tag = nlu_vector[index]\n",
    "            if cur_tag == 'O' and pre_tag.startswith('B-'):\n",
    "                slot = pre_tag.split('-')[1]\n",
    "                slot_val_str = ' '.join(words[pre_tag_index:index])\n",
    "                slot_val_dict[slot] = slot_val_str\n",
    "            elif cur_tag.startswith('B-') and pre_tag.startswith('B-'):\n",
    "                slot = pre_tag.split('-')[1]\n",
    "                slot_val_str = ' '.join(words[pre_tag_index:index])\n",
    "                slot_val_dict[slot] = slot_val_str\n",
    "            elif cur_tag.startswith('B-') and pre_tag.startswith('I-'):\n",
    "                if cur_tag.split('-')[1] != pre_tag.split('-')[1]:           \n",
    "                    slot = pre_tag.split('-')[1]\n",
    "                    slot_val_str = ' '.join(words[pre_tag_index:index])\n",
    "                    slot_val_dict[slot] = slot_val_str\n",
    "            elif cur_tag == 'O' and pre_tag.startswith('I-'):\n",
    "                slot = pre_tag.split('-')[1]\n",
    "                slot_val_str = ' '.join(words[pre_tag_index:index])\n",
    "                slot_val_dict[slot] = slot_val_str\n",
    "               \n",
    "            if cur_tag.startswith('B-'): pre_tag_index = index\n",
    "        \n",
    "            pre_tag = cur_tag\n",
    "            index += 1\n",
    "    \n",
    "        if cur_tag.startswith('B-') or cur_tag.startswith('I-'):\n",
    "            slot = cur_tag.split('-')[1]\n",
    "            slot_val_str = ' '.join(words[pre_tag_index:-1])\n",
    "            slot_val_dict[slot] = slot_val_str\n",
    "    \n",
    "        if intent != 'null':\n",
    "            arr = intent.split('+')\n",
    "            diaact['diaact'] = arr[0]\n",
    "            diaact['request_slots'] = {}\n",
    "            for ele in arr[1:]: \n",
    "                #request_slots.append(ele)\n",
    "                diaact['request_slots'][ele] = 'UNK'\n",
    "        \n",
    "        diaact['inform_slots'] = slot_val_dict\n",
    "         \n",
    "        # add rule here\n",
    "        for slot in diaact['inform_slots'].keys():\n",
    "            slot_val = diaact['inform_slots'][slot]\n",
    "            if slot_val.startswith('bos'): \n",
    "                slot_val = slot_val.replace('bos', '', 1)\n",
    "                diaact['inform_slots'][slot] = slot_val.strip(' ')\n",
    "        \n",
    "        self.refine_diaact_by_rules(diaact)\n",
    "        return diaact\n",
    "\n",
    "    def refine_diaact_by_rules(self, diaact):\n",
    "        \"\"\" refine the dia_act by rules \"\"\"\n",
    "        \n",
    "        # rule for taskcomplete\n",
    "        if 'request_slots' in diaact.keys():\n",
    "            if 'taskcomplete' in diaact['request_slots'].keys():\n",
    "                del diaact['request_slots']['taskcomplete']\n",
    "                diaact['inform_slots']['taskcomplete'] = 'PLACEHOLDER'\n",
    "        \n",
    "            # rule for request\n",
    "            if len(diaact['request_slots'])>0: diaact['diaact'] = 'request'\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def diaact_penny_string(self, dia_act):\n",
    "        \"\"\" Convert the Dia-Act into penny string \"\"\"\n",
    "        \n",
    "        penny_str = \"\"\n",
    "        penny_str = dia_act['diaact'] + \"(\"\n",
    "        for slot in dia_act['request_slots'].keys():\n",
    "            penny_str += slot + \";\"\n",
    "    \n",
    "        for slot in dia_act['inform_slots'].keys():\n",
    "            slot_val_str = slot + \"=\"\n",
    "            if len(dia_act['inform_slots'][slot]) == 1:\n",
    "                slot_val_str += dia_act['inform_slots'][slot][0]\n",
    "            else:\n",
    "                slot_val_str += \"{\"\n",
    "                for slot_val in dia_act['inform_slots'][slot]:\n",
    "                    slot_val_str += slot_val + \"#\"\n",
    "                slot_val_str = slot_val_str[:-1]\n",
    "                slot_val_str += \"}\"\n",
    "            penny_str += slot_val_str + \";\"\n",
    "    \n",
    "        if penny_str[-1] == \";\": penny_str = penny_str[:-1]\n",
    "        penny_str += \")\"\n",
    "        return penny_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlg_model_path = params['nlg_model_path']\n",
    "diaact_nl_pairs = params['diaact_nl_pairs']\n",
    "nlg_model = nlg()\n",
    "nlg_model.load_nlg_model(nlg_model_path)\n",
    "nlg_model.load_predefine_act_nl_pairs(diaact_nl_pairs)\n",
    "\n",
    "agent.set_nlg_model(nlg_model)\n",
    "user_sim.set_nlg_model(nlg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_model_path = params['nlu_model_path']\n",
    "nlu_model = nlu()\n",
    "nlu_model.load_nlu_model(nlu_model_path)\n",
    "\n",
    "agent.set_nlu_model(nlu_model)\n",
    "user_sim.set_nlu_model(nlu_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KBHelper:\n",
    "    \"\"\" An assistant to fill in values for the agent (which knows about slots of values) \"\"\"\n",
    "    \n",
    "    def __init__(self, movie_dictionary):\n",
    "        \"\"\" Constructor for a KBHelper \"\"\"\n",
    "        \n",
    "        self.movie_dictionary = movie_dictionary\n",
    "        self.cached_kb = defaultdict(list)\n",
    "        self.cached_kb_slot = defaultdict(list)\n",
    "\n",
    "\n",
    "    def fill_inform_slots(self, inform_slots_to_be_filled, current_slots):\n",
    "        \"\"\" Takes unfilled inform slots and current_slots, returns dictionary of filled informed slots (with values)\n",
    "        Arguments:\n",
    "        inform_slots_to_be_filled   --  Something that looks like {starttime:None, theater:None} where starttime and theater are slots that the agent needs filled\n",
    "        current_slots               --  Contains a record of all filled slots in the conversation so far - for now, just use current_slots['inform_slots'] which is a dictionary of the already filled-in slots\n",
    "        Returns:\n",
    "        filled_in_slots             --  A dictionary of form {slot1:value1, slot2:value2} for each sloti in inform_slots_to_be_filled\n",
    "        \"\"\"\n",
    "        \n",
    "        kb_results = self.available_results_from_kb(current_slots)\n",
    "        if auto_suggest == 1:\n",
    "            print 'Number of movies in KB satisfying current constraints: ', len(kb_results)\n",
    "\n",
    "        filled_in_slots = {}\n",
    "        if 'taskcomplete' in inform_slots_to_be_filled.keys():\n",
    "            filled_in_slots.update(current_slots['inform_slots'])\n",
    "        \n",
    "        for slot in inform_slots_to_be_filled.keys():\n",
    "            if slot == 'numberofpeople':\n",
    "                if slot in current_slots['inform_slots'].keys():\n",
    "                    filled_in_slots[slot] = current_slots['inform_slots'][slot]\n",
    "                elif slot in inform_slots_to_be_filled.keys():\n",
    "                    filled_in_slots[slot] = inform_slots_to_be_filled[slot]\n",
    "                continue\n",
    "\n",
    "            if slot == 'ticket' or slot == 'taskcomplete':\n",
    "                filled_in_slots[slot] = TICKET_AVAILABLE if len(kb_results)>0 else NO_VALUE_MATCH\n",
    "                continue\n",
    "            \n",
    "            if slot == 'closing': continue\n",
    "\n",
    "            ####################################################################\n",
    "            #   Grab the value for the slot with the highest count and fill it\n",
    "            ####################################################################\n",
    "            values_dict = self.available_slot_values(slot, kb_results)\n",
    "\n",
    "            values_counts = [(v, values_dict[v]) for v in values_dict.keys()]\n",
    "            if len(values_counts) > 0:\n",
    "                filled_in_slots[slot] = sorted(values_counts, key = lambda x: -x[1])[0][0]\n",
    "            else:\n",
    "                filled_in_slots[slot] = NO_VALUE_MATCH #\"NO VALUE MATCHES SNAFU!!!\"\n",
    "           \n",
    "        return filled_in_slots\n",
    "\n",
    "\n",
    "    def available_slot_values(self, slot, kb_results):\n",
    "        \"\"\" Return the set of values available for the slot based on the current constraints \"\"\"\n",
    "        \n",
    "        slot_values = {}\n",
    "        for movie_id in kb_results.keys():\n",
    "            if slot in kb_results[movie_id].keys():\n",
    "                slot_val = kb_results[movie_id][slot]\n",
    "                if slot_val in slot_values.keys():\n",
    "                    slot_values[slot_val] += 1\n",
    "                else: slot_values[slot_val] = 1\n",
    "        return slot_values\n",
    "\n",
    "    def available_results_from_kb(self, current_slots):\n",
    "        \"\"\" Return the available movies in the movie_kb based on the current constraints \"\"\"\n",
    "        \n",
    "        ret_result = []\n",
    "        current_slots = current_slots['inform_slots']\n",
    "        constrain_keys = current_slots.keys()\n",
    "\n",
    "        constrain_keys = filter(lambda k : k != 'ticket' and \\\n",
    "                                           k != 'numberofpeople' and \\\n",
    "                                           k!= 'taskcomplete' and \\\n",
    "                                           k != 'closing' , constrain_keys)\n",
    "        constrain_keys = [k for k in constrain_keys if current_slots[k] != I_DO_NOT_CARE]\n",
    "\n",
    "        query_idx_keys = frozenset(current_slots.items())\n",
    "        cached_kb_ret = self.cached_kb[query_idx_keys]\n",
    "\n",
    "        cached_kb_length = len(cached_kb_ret) if cached_kb_ret != None else -1\n",
    "        if cached_kb_length > 0:\n",
    "            return dict(cached_kb_ret)\n",
    "        elif cached_kb_length == -1:\n",
    "            return dict([])\n",
    "\n",
    "        # kb_results = copy.deepcopy(self.movie_dictionary)\n",
    "        for id in self.movie_dictionary.keys():\n",
    "            kb_keys = self.movie_dictionary[id].keys()\n",
    "            if len(set(constrain_keys).union(set(kb_keys)) ^ (set(constrain_keys) ^ set(kb_keys))) == len(\n",
    "                    constrain_keys):\n",
    "                match = True\n",
    "                for idx, k in enumerate(constrain_keys):\n",
    "                    if str(current_slots[k]).lower() == str(self.movie_dictionary[id][k]).lower():\n",
    "                        continue\n",
    "                    else:\n",
    "                        match = False\n",
    "                if match:\n",
    "                    self.cached_kb[query_idx_keys].append((id, self.movie_dictionary[id]))\n",
    "                    ret_result.append((id, self.movie_dictionary[id]))\n",
    "\n",
    "            # for slot in current_slots['inform_slots'].keys():\n",
    "            #     if slot == 'ticket' or slot == 'numberofpeople' or slot == 'taskcomplete' or slot == 'closing': continue\n",
    "            #     if current_slots['inform_slots'][slot] == dialog_config.I_DO_NOT_CARE: continue\n",
    "            #\n",
    "            #     if slot not in self.movie_dictionary[movie_id].keys():\n",
    "            #         if movie_id in kb_results.keys():\n",
    "            #             del kb_results[movie_id]\n",
    "            #     else:\n",
    "            #         if current_slots['inform_slots'][slot].lower() != self.movie_dictionary[movie_id][slot].lower():\n",
    "            #             if movie_id in kb_results.keys():\n",
    "            #                 del kb_results[movie_id]\n",
    "            \n",
    "        if len(ret_result) == 0:\n",
    "            self.cached_kb[query_idx_keys] = None\n",
    "\n",
    "        ret_result = dict(ret_result)\n",
    "        return ret_result\n",
    "    \n",
    "    def available_results_from_kb_for_slots(self, inform_slots):\n",
    "        \"\"\" Return the count statistics for each constraint in inform_slots \"\"\"\n",
    "        \n",
    "        kb_results = {key:0 for key in inform_slots.keys()}\n",
    "        kb_results['matching_all_constraints'] = 0\n",
    "        \n",
    "        query_idx_keys = frozenset(inform_slots.items())\n",
    "        cached_kb_slot_ret = self.cached_kb_slot[query_idx_keys]\n",
    "\n",
    "        if len(cached_kb_slot_ret) > 0:\n",
    "            return cached_kb_slot_ret[0]\n",
    "\n",
    "        for movie_id in self.movie_dictionary.keys():\n",
    "            all_slots_match = 1\n",
    "            for slot in inform_slots.keys():\n",
    "                if slot == 'ticket' or inform_slots[slot] == I_DO_NOT_CARE:\n",
    "                    continue\n",
    "\n",
    "                if slot in self.movie_dictionary[movie_id].keys():\n",
    "                    if inform_slots[slot].lower() == self.movie_dictionary[movie_id][slot].lower():\n",
    "                        kb_results[slot] += 1\n",
    "                    else:\n",
    "                        all_slots_match = 0\n",
    "                else:\n",
    "                    all_slots_match = 0\n",
    "            kb_results['matching_all_constraints'] += all_slots_match\n",
    "\n",
    "        self.cached_kb_slot[query_idx_keys].append(kb_results)\n",
    "        return kb_results\n",
    "\n",
    "    \n",
    "    def database_results_for_agent(self, current_slots):\n",
    "        \"\"\" A dictionary of the number of results matching each current constraint. The agent needs this to decide what to do next. \"\"\"\n",
    "\n",
    "        database_results ={} # { date:100, distanceconstraints:60, theater:30,  matching_all_constraints: 5}\n",
    "        database_results = self.available_results_from_kb_for_slots(current_slots['inform_slots'])\n",
    "        return database_results\n",
    "    \n",
    "    def suggest_slot_values(self, request_slots, current_slots):\n",
    "        \"\"\" Return the suggest slot values \"\"\"\n",
    "        \n",
    "        avail_kb_results = self.available_results_from_kb(current_slots)\n",
    "        return_suggest_slot_vals = {}\n",
    "        for slot in request_slots.keys():\n",
    "            avail_values_dict = self.available_slot_values(slot, avail_kb_results)\n",
    "            values_counts = [(v, avail_values_dict[v]) for v in avail_values_dict.keys()]\n",
    "            \n",
    "            if len(values_counts) > 0:\n",
    "                return_suggest_slot_vals[slot] = []\n",
    "                sorted_dict = sorted(values_counts, key = lambda x: -x[1])\n",
    "                for k in sorted_dict: return_suggest_slot_vals[slot].append(k[0])\n",
    "            else:\n",
    "                return_suggest_slot_vals[slot] = []\n",
    "        \n",
    "        return return_suggest_slot_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateTracker:\n",
    "    \"\"\" The state tracker maintains a record of which request slots are filled and which inform slots are filled \"\"\"\n",
    "\n",
    "    def __init__(self, act_set, slot_set, movie_dictionary):\n",
    "        \"\"\" constructor for statetracker takes movie knowledge base and initializes a new episode\n",
    "        Arguments:\n",
    "        act_set                 --  The set of all acts availavle\n",
    "        slot_set                --  The total set of available slots\n",
    "        movie_dictionary        --  A representation of all the available movies. Generally this object is accessed via the KBHelper class\n",
    "        Class Variables:\n",
    "        history_vectors         --  A record of the current dialog so far in vector format (act-slot, but no values)\n",
    "        history_dictionaries    --  A record of the current dialog in dictionary format\n",
    "        current_slots           --  A dictionary that keeps a running record of which slots are filled current_slots['inform_slots'] and which are requested current_slots['request_slots'] (but not filed)\n",
    "        action_dimension        --  # TODO indicates the dimensionality of the vector representaiton of the action\n",
    "        kb_result_dimension     --  A single integer denoting the dimension of the kb_results features.\n",
    "        turn_count              --  A running count of which turn we are at in the present dialog\n",
    "        \"\"\"\n",
    "        self.movie_dictionary = movie_dictionary\n",
    "        self.initialize_episode()\n",
    "        self.history_vectors = None\n",
    "        self.history_dictionaries = None\n",
    "        self.current_slots = None\n",
    "        self.action_dimension = 10      # TODO REPLACE WITH REAL VALUE\n",
    "        self.kb_result_dimension = 10   # TODO  REPLACE WITH REAL VALUE\n",
    "        self.turn_count = 0\n",
    "        self.kb_helper = KBHelper(movie_dictionary)\n",
    "        \n",
    "\n",
    "    def initialize_episode(self):\n",
    "        \"\"\" Initialize a new episode (dialog), flush the current state and tracked slots \"\"\"\n",
    "        \n",
    "        self.action_dimension = 10\n",
    "        self.history_vectors = np.zeros((1, self.action_dimension))\n",
    "        self.history_dictionaries = []\n",
    "        self.turn_count = 0\n",
    "        self.current_slots = {}\n",
    "        \n",
    "        self.current_slots['inform_slots'] = {}\n",
    "        self.current_slots['request_slots'] = {}\n",
    "        self.current_slots['proposed_slots'] = {}\n",
    "        self.current_slots['agent_request_slots'] = {}\n",
    "\n",
    "\n",
    "    def dialog_history_vectors(self):\n",
    "        \"\"\" Return the dialog history (both user and agent actions) in vector representation \"\"\"\n",
    "        return self.history_vectors\n",
    "\n",
    "\n",
    "    def dialog_history_dictionaries(self):\n",
    "        \"\"\"  Return the dictionary representation of the dialog history (includes values) \"\"\"\n",
    "        return self.history_dictionaries\n",
    "\n",
    "\n",
    "    def kb_results_for_state(self):\n",
    "        \"\"\" Return the information about the database results based on the currently informed slots \"\"\"\n",
    "        ########################################################################\n",
    "        # TODO Calculate results based on current informed slots\n",
    "        ########################################################################\n",
    "        kb_results = self.kb_helper.database_results_for_agent(self.current_slots) # replace this with something less ridiculous\n",
    "        # TODO turn results into vector (from dictionary)\n",
    "        results = np.zeros((0, self.kb_result_dimension))\n",
    "        return results\n",
    "        \n",
    "\n",
    "    def get_state_for_agent(self):\n",
    "        \"\"\" Get the state representatons to send to agent \"\"\"\n",
    "        #state = {'user_action': self.history_dictionaries[-1], 'current_slots': self.current_slots, 'kb_results': self.kb_results_for_state()}\n",
    "        state = {'user_action': self.history_dictionaries[-1], 'current_slots': self.current_slots, #'kb_results': self.kb_results_for_state(), \n",
    "                 'kb_results_dict':self.kb_helper.database_results_for_agent(self.current_slots), 'turn': self.turn_count, 'history': self.history_dictionaries, \n",
    "                 'agent_action': self.history_dictionaries[-2] if len(self.history_dictionaries) > 1 else None}\n",
    "        return copy.deepcopy(state)\n",
    "    \n",
    "    def get_suggest_slots_values(self, request_slots):\n",
    "        \"\"\" Get the suggested values for request slots \"\"\"\n",
    "        \n",
    "        suggest_slot_vals = {}\n",
    "        if len(request_slots) > 0: \n",
    "            suggest_slot_vals = self.kb_helper.suggest_slot_values(request_slots, self.current_slots)\n",
    "        \n",
    "        return suggest_slot_vals\n",
    "    \n",
    "    def get_current_kb_results(self):\n",
    "        \"\"\" get the kb_results for current state \"\"\"\n",
    "        kb_results = self.kb_helper.available_results_from_kb(self.current_slots)\n",
    "        return kb_results\n",
    "    \n",
    "    \n",
    "    def update(self, agent_action=None, user_action=None):\n",
    "        \"\"\" Update the state based on the latest action \"\"\"\n",
    "\n",
    "        ########################################################################\n",
    "        #  Make sure that the function was called properly\n",
    "        ########################################################################\n",
    "        assert(not (user_action and agent_action))\n",
    "        assert(user_action or agent_action)\n",
    "\n",
    "        ########################################################################\n",
    "        #   Update state to reflect a new action by the agent.\n",
    "        ########################################################################\n",
    "        if agent_action:\n",
    "            \n",
    "            ####################################################################\n",
    "            #   Handles the act_slot response (with values needing to be filled)\n",
    "            ####################################################################\n",
    "            if agent_action['act_slot_response']:\n",
    "                response = copy.deepcopy(agent_action['act_slot_response'])\n",
    "                \n",
    "                inform_slots = self.kb_helper.fill_inform_slots(response['inform_slots'], self.current_slots) # TODO this doesn't actually work yet, remove this warning when kb_helper is functional\n",
    "                agent_action_values = {'turn': self.turn_count, 'speaker': \"agent\", 'diaact': response['diaact'], 'inform_slots': inform_slots, 'request_slots':response['request_slots']}\n",
    "                \n",
    "                agent_action['act_slot_response'].update({'diaact': response['diaact'], 'inform_slots': inform_slots, 'request_slots':response['request_slots'], 'turn':self.turn_count})\n",
    "                \n",
    "            elif agent_action['act_slot_value_response']:\n",
    "                agent_action_values = copy.deepcopy(agent_action['act_slot_value_response'])\n",
    "                # print(\"Updating state based on act_slot_value action from agent\")\n",
    "                agent_action_values['turn'] = self.turn_count\n",
    "                agent_action_values['speaker'] = \"agent\"\n",
    "                \n",
    "            ####################################################################\n",
    "            #   This code should execute regardless of which kind of agent produced action\n",
    "            ####################################################################\n",
    "            for slot in agent_action_values['inform_slots'].keys():\n",
    "                self.current_slots['proposed_slots'][slot] = agent_action_values['inform_slots'][slot]\n",
    "                self.current_slots['inform_slots'][slot] = agent_action_values['inform_slots'][slot] # add into inform_slots\n",
    "                if slot in self.current_slots['request_slots'].keys():\n",
    "                    del self.current_slots['request_slots'][slot]\n",
    "\n",
    "            for slot in agent_action_values['request_slots'].keys():\n",
    "                if slot not in self.current_slots['agent_request_slots']:\n",
    "                    self.current_slots['agent_request_slots'][slot] = \"UNK\"\n",
    "\n",
    "            self.history_dictionaries.append(agent_action_values)\n",
    "            current_agent_vector = np.ones((1, self.action_dimension))\n",
    "            self.history_vectors = np.vstack([self.history_vectors, current_agent_vector])\n",
    "                            \n",
    "        ########################################################################\n",
    "        #   Update the state to reflect a new action by the user\n",
    "        ########################################################################\n",
    "        elif user_action:\n",
    "            \n",
    "            ####################################################################\n",
    "            #   Update the current slots\n",
    "            ####################################################################\n",
    "            for slot in user_action['inform_slots'].keys():\n",
    "                self.current_slots['inform_slots'][slot] = user_action['inform_slots'][slot]\n",
    "                if slot in self.current_slots['request_slots'].keys():\n",
    "                    del self.current_slots['request_slots'][slot]\n",
    "\n",
    "            for slot in user_action['request_slots'].keys():\n",
    "                if slot not in self.current_slots['request_slots']:\n",
    "                    self.current_slots['request_slots'][slot] = \"UNK\"\n",
    "            \n",
    "            self.history_vectors = np.vstack([self.history_vectors, np.zeros((1,self.action_dimension))])\n",
    "            new_move = {'turn': self.turn_count, 'speaker': \"user\", 'request_slots': user_action['request_slots'], 'inform_slots': user_action['inform_slots'], 'diaact': user_action['diaact']}\n",
    "            self.history_dictionaries.append(copy.deepcopy(new_move))\n",
    "\n",
    "        ########################################################################\n",
    "        #   This should never happen if the asserts passed\n",
    "        ########################################################################\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        ########################################################################\n",
    "        #   This code should execute after update code regardless of what kind of action (agent/user)\n",
    "        ########################################################################\n",
    "        self.turn_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DialogManager:\n",
    "    \"\"\" A dialog manager to mediate the interaction between an agent and a customer \"\"\"\n",
    "    \n",
    "    def __init__(self, agent, user, act_set, slot_set, movie_dictionary):\n",
    "        self.agent = agent\n",
    "        self.user = user\n",
    "        self.act_set = act_set\n",
    "        self.slot_set = slot_set\n",
    "        self.state_tracker = StateTracker(act_set, slot_set, movie_dictionary)\n",
    "        self.user_action = None\n",
    "        self.reward = 0\n",
    "        self.episode_over = False\n",
    "\n",
    "    def initialize_episode(self):\n",
    "        \"\"\" Refresh state for new dialog \"\"\"\n",
    "        \n",
    "        self.reward = 0\n",
    "        self.episode_over = False\n",
    "        self.state_tracker.initialize_episode()\n",
    "        self.user_action = self.user.initialize_episode()\n",
    "        self.state_tracker.update(user_action = self.user_action)\n",
    "        \n",
    "        if run_mode < 3:\n",
    "            print (\"New episode, user goal:\")\n",
    "            print json.dumps(self.user.goal, indent=2)\n",
    "        self.print_function(user_action = self.user_action)\n",
    "            \n",
    "        self.agent.initialize_episode()\n",
    "\n",
    "    def next_turn(self, record_training_data=True):\n",
    "        \"\"\" This function initiates each subsequent exchange between agent and user (agent first) \"\"\"\n",
    "        \n",
    "        ########################################################################\n",
    "        #   CALL AGENT TO TAKE HER TURN\n",
    "        ########################################################################\n",
    "        self.state = self.state_tracker.get_state_for_agent()\n",
    "        self.agent_action = self.agent.state_to_action(self.state)\n",
    "        \n",
    "        ########################################################################\n",
    "        #   Register AGENT action with the state_tracker\n",
    "        ########################################################################\n",
    "        self.state_tracker.update(agent_action=self.agent_action)\n",
    "        \n",
    "        self.agent.add_nl_to_action(self.agent_action) # add NL to Agent Dia_Act\n",
    "        self.print_function(agent_action = self.agent_action['act_slot_response'])\n",
    "        \n",
    "        ########################################################################\n",
    "        #   CALL USER TO TAKE HER TURN\n",
    "        ########################################################################\n",
    "        self.sys_action = self.state_tracker.dialog_history_dictionaries()[-1]\n",
    "        self.user_action, self.episode_over, dialog_status = self.user.next(self.sys_action)\n",
    "        self.reward = self.reward_function(dialog_status)\n",
    "        \n",
    "        ########################################################################\n",
    "        #   Update state tracker with latest user action\n",
    "        ########################################################################\n",
    "        if self.episode_over != True:\n",
    "            self.state_tracker.update(user_action = self.user_action)\n",
    "            self.print_function(user_action = self.user_action)\n",
    "\n",
    "        ########################################################################\n",
    "        #  Inform agent of the outcome for this timestep (s_t, a_t, r, s_{t+1}, episode_over)\n",
    "        ########################################################################\n",
    "        if record_training_data:\n",
    "            self.agent.register_experience_replay_tuple(self.state, self.agent_action, self.reward, self.state_tracker.get_state_for_agent(), self.episode_over)\n",
    "        \n",
    "        return (self.episode_over, self.reward)\n",
    "\n",
    "    \n",
    "    def reward_function(self, dialog_status):\n",
    "        \"\"\" Reward Function 1: a reward function based on the dialog_status \"\"\"\n",
    "        if dialog_status == FAILED_DIALOG:\n",
    "            reward = -self.user.max_turn #10\n",
    "        elif dialog_status == SUCCESS_DIALOG:\n",
    "            reward = 2*self.user.max_turn #20\n",
    "        else:\n",
    "            reward = -1\n",
    "        return reward\n",
    "    \n",
    "    def reward_function_without_penalty(self, dialog_status):\n",
    "        \"\"\" Reward Function 2: a reward function without penalty on per turn and failure dialog \"\"\"\n",
    "        if dialog_status == dialog_config.FAILED_DIALOG:\n",
    "            reward = 0\n",
    "        elif dialog_status == dialog_config.SUCCESS_DIALOG:\n",
    "            reward = 2*self.user.max_turn\n",
    "        else:\n",
    "            reward = 0\n",
    "        return reward\n",
    "    \n",
    "    \n",
    "    def print_function(self, agent_action=None, user_action=None):\n",
    "        \"\"\" Print Function \"\"\"\n",
    "            \n",
    "        if agent_action:\n",
    "            if run_mode == 0:\n",
    "                if self.agent.__class__.__name__ != 'AgentCmd':\n",
    "                    print (\"Turn %d sys: %s\" % (agent_action['turn'], agent_action['nl']))\n",
    "            elif run_mode == 1:\n",
    "                if self.agent.__class__.__name__ != 'AgentCmd':\n",
    "                    print(\"Turn %d sys: %s, inform_slots: %s, request slots: %s\" % (agent_action['turn'], agent_action['diaact'], agent_action['inform_slots'], agent_action['request_slots']))\n",
    "            elif run_mode == 2: # debug mode\n",
    "                print(\"Turn %d sys: %s, inform_slots: %s, request slots: %s\" % (agent_action['turn'], agent_action['diaact'], agent_action['inform_slots'], agent_action['request_slots']))\n",
    "                print (\"Turn %d sys: %s\" % (agent_action['turn'], agent_action['nl']))\n",
    "            \n",
    "            if auto_suggest == 1:\n",
    "                print('(Suggested Values: %s)' % (self.state_tracker.get_suggest_slots_values(agent_action['request_slots'])))\n",
    "        elif user_action:\n",
    "            if run_mode == 0:\n",
    "                print (\"Turn %d usr: %s\" % (user_action['turn'], user_action['nl']))\n",
    "            elif run_mode == 1: \n",
    "                print (\"Turn %s usr: %s, inform_slots: %s, request_slots: %s\" % (user_action['turn'], user_action['diaact'], user_action['inform_slots'], user_action['request_slots']))\n",
    "            elif run_mode == 2: # debug mode, show both\n",
    "                print (\"Turn %d usr: %s, inform_slots: %s, request_slots: %s\" % (user_action['turn'], user_action['diaact'], user_action['inform_slots'], user_action['request_slots']))\n",
    "                print (\"Turn %d usr: %s\" % (user_action['turn'], user_action['nl']))\n",
    "            \n",
    "            if self.agent.__class__.__name__ == 'AgentCmd': # command line agent\n",
    "                user_request_slots = user_action['request_slots']\n",
    "                if 'ticket'in user_request_slots.keys(): del user_request_slots['ticket']\n",
    "                if len(user_request_slots) > 0:\n",
    "                    possible_values = self.state_tracker.get_suggest_slots_values(user_action['request_slots'])\n",
    "                    for slot in possible_values.keys():\n",
    "                        if len(possible_values[slot]) > 0:\n",
    "                            print('(Suggested Values: %s: %s)' % (slot, possible_values[slot]))\n",
    "                        elif len(possible_values[slot]) == 0:\n",
    "                            print('(Suggested Values: there is no available %s)' % (slot))\n",
    "                else:\n",
    "                    kb_results = self.state_tracker.get_current_kb_results()\n",
    "                    print ('(Number of movies in KB satisfying current constraints: %s)' % len(kb_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_manager = DialogManager(agent, user_sim, act_set, slot_set, movie_kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = {'successes': 0, 'count': 0, 'cumulative_reward': 0}\n",
    "\n",
    "simulation_epoch_size = params['simulation_epoch_size']\n",
    "batch_size = params['batch_size'] # default = 16\n",
    "warm_start = params['warm_start']\n",
    "warm_start_epochs = params['warm_start_epochs']\n",
    "\n",
    "success_rate_threshold = params['success_rate_threshold']\n",
    "save_check_point = params['save_check_point']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Best Model and Performance Records \"\"\"\n",
    "best_model = {}\n",
    "best_res = {'success_rate': 0, 'ave_reward':float('-inf'), 'ave_turns': float('inf'), 'epoch':0}\n",
    "best_model['model'] = copy.deepcopy(agent)\n",
    "best_res['success_rate'] = 0\n",
    "\n",
    "performance_records = {}\n",
    "performance_records['success_rate'] = {}\n",
    "performance_records['ave_turns'] = {}\n",
    "performance_records['ave_reward'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Save model \"\"\"\n",
    "def save_model(path, agt, success_rate, agent, best_epoch, cur_epoch):\n",
    "    filename = 'agt_%s_%s_%s_%.5f.p' % (agt, best_epoch, cur_epoch, success_rate)\n",
    "    filepath = os.path.join(path, filename)\n",
    "    checkpoint = {}\n",
    "    if agt == 9: checkpoint['model'] = copy.deepcopy(agent.dqn.model)\n",
    "    checkpoint['params'] = params\n",
    "    try:\n",
    "        pickle.dump(checkpoint, open(filepath, \"wb\"))\n",
    "        print 'saved model in %s' % (filepath, )\n",
    "    except Exception, e:\n",
    "        print 'Error: Writing model fails: %s' % (filepath, )\n",
    "        print e\n",
    "\n",
    "\"\"\" save performance numbers \"\"\"\n",
    "def save_performance_records(path, agt, records):\n",
    "    filename = 'agt_%s_performance_records.json' % (agt)\n",
    "    filepath = os.path.join(path, filename)\n",
    "    try:\n",
    "        json.dump(records, open(filepath, \"wb\"))\n",
    "        print 'saved model in %s' % (filepath, )\n",
    "    except Exception, e:\n",
    "        print 'Error: Writing model fails: %s' % (filepath, )\n",
    "        print e\n",
    "\n",
    "\"\"\" Run N simulation Dialogues \"\"\"\n",
    "def simulation_epoch(simulation_epoch_size):\n",
    "    successes = 0\n",
    "    cumulative_reward = 0\n",
    "    cumulative_turns = 0\n",
    "    \n",
    "    res = {}\n",
    "    for episode in xrange(simulation_epoch_size):\n",
    "        dialog_manager.initialize_episode()\n",
    "        episode_over = False\n",
    "        while(not episode_over):\n",
    "            episode_over, reward = dialog_manager.next_turn()\n",
    "            cumulative_reward += reward\n",
    "            if episode_over:\n",
    "                if reward > 0: \n",
    "                    successes += 1\n",
    "                    print (\"simulation episode %s: Success\" % (episode))\n",
    "                else: print (\"simulation episode %s: Fail\" % (episode))\n",
    "                cumulative_turns += dialog_manager.state_tracker.turn_count\n",
    "    \n",
    "    res['success_rate'] = float(successes)/simulation_epoch_size\n",
    "    res['ave_reward'] = float(cumulative_reward)/simulation_epoch_size\n",
    "    res['ave_turns'] = float(cumulative_turns)/simulation_epoch_size\n",
    "    print (\"simulation success rate %s, ave reward %s, ave turns %s\" % (res['success_rate'], res['ave_reward'], res['ave_turns']))\n",
    "    return res\n",
    "\n",
    "\"\"\" Warm_Start Simulation (by Rule Policy) \"\"\"\n",
    "def warm_start_simulation():\n",
    "    successes = 0\n",
    "    cumulative_reward = 0\n",
    "    cumulative_turns = 0\n",
    "    \n",
    "    res = {}\n",
    "    warm_start_run_epochs = 0\n",
    "    for episode in xrange(warm_start_epochs):\n",
    "        dialog_manager.initialize_episode()\n",
    "        episode_over = False\n",
    "        while(not episode_over):\n",
    "            episode_over, reward = dialog_manager.next_turn()\n",
    "            cumulative_reward += reward\n",
    "            if episode_over:\n",
    "                if reward > 0: \n",
    "                    successes += 1\n",
    "                    print (\"warm_start simulation episode %s: Success\" % (episode))\n",
    "                else: print (\"warm_start simulation episode %s: Fail\" % (episode))\n",
    "                cumulative_turns += dialog_manager.state_tracker.turn_count\n",
    "        \n",
    "        warm_start_run_epochs += 1\n",
    "        \n",
    "        if len(agent.experience_replay_pool) >= agent.experience_replay_pool_size:\n",
    "            break\n",
    "        \n",
    "    agent.warm_start = 2\n",
    "    res['success_rate'] = float(successes)/warm_start_run_epochs\n",
    "    res['ave_reward'] = float(cumulative_reward)/warm_start_run_epochs\n",
    "    res['ave_turns'] = float(cumulative_turns)/warm_start_run_epochs\n",
    "    print (\"Warm_Start %s epochs, success rate %s, ave reward %s, ave turns %s\" % (episode+1, res['success_rate'], res['ave_reward'], res['ave_turns']))\n",
    "    print (\"Current experience replay buffer size %s\" % (len(agent.experience_replay_pool)))\n",
    "\n",
    "\n",
    "\n",
    "def run_episodes(count, status):\n",
    "    successes = 0\n",
    "    cumulative_reward = 0\n",
    "    cumulative_turns = 0\n",
    "    \n",
    "    if agt == 9 and params['trained_model_path'] == None and warm_start == 1:\n",
    "        print ('warm_start starting ...')\n",
    "        warm_start_simulation()\n",
    "        print ('warm_start finished, start RL training ...')\n",
    "    \n",
    "    for episode in xrange(count):\n",
    "        print (\"Episode: %s\" % (episode))\n",
    "        dialog_manager.initialize_episode()\n",
    "        episode_over = False\n",
    "        \n",
    "        while(not episode_over):\n",
    "            episode_over, reward = dialog_manager.next_turn()\n",
    "            cumulative_reward += reward\n",
    "                \n",
    "            if episode_over:\n",
    "                if reward > 0:\n",
    "                    print (\"Successful Dialog!\")\n",
    "                    successes += 1\n",
    "                else: print (\"Failed Dialog!\")\n",
    "                \n",
    "                cumulative_turns += dialog_manager.state_tracker.turn_count\n",
    "        \n",
    "        # simulation\n",
    "        if agt == 9 and params['trained_model_path'] == None:\n",
    "            agent.predict_mode = True\n",
    "            simulation_res = simulation_epoch(simulation_epoch_size)\n",
    "            \n",
    "            performance_records['success_rate'][episode] = simulation_res['success_rate']\n",
    "            performance_records['ave_turns'][episode] = simulation_res['ave_turns']\n",
    "            performance_records['ave_reward'][episode] = simulation_res['ave_reward']\n",
    "            \n",
    "            if simulation_res['success_rate'] >= best_res['success_rate']:\n",
    "                if simulation_res['success_rate'] >= success_rate_threshold: # threshold = 0.30\n",
    "                    agent.experience_replay_pool = [] \n",
    "                    simulation_epoch(simulation_epoch_size)\n",
    "                \n",
    "            if simulation_res['success_rate'] > best_res['success_rate']:\n",
    "                best_model['model'] = copy.deepcopy(agent)\n",
    "                best_res['success_rate'] = simulation_res['success_rate']\n",
    "                best_res['ave_reward'] = simulation_res['ave_reward']\n",
    "                best_res['ave_turns'] = simulation_res['ave_turns']\n",
    "                best_res['epoch'] = episode\n",
    "                \n",
    "            agent.clone_dqn = copy.deepcopy(agent.dqn)\n",
    "            agent.train(batch_size, 1)\n",
    "            agent.predict_mode = False\n",
    "            \n",
    "            print (\"Simulation success rate %s, Ave reward %s, Ave turns %s, Best success rate %s\" % (performance_records['success_rate'][episode], performance_records['ave_reward'][episode], performance_records['ave_turns'][episode], best_res['success_rate']))\n",
    "            if episode % save_check_point == 0 and params['trained_model_path'] == None: # save the model every 10 episodes\n",
    "                save_model(params['write_model_dir'], agt, best_res['success_rate'], best_model['model'], best_res['epoch'], episode)\n",
    "                save_performance_records(params['write_model_dir'], agt, performance_records)\n",
    "        \n",
    "        print(\"Progress: %s / %s, Success rate: %s / %s Avg reward: %.2f Avg turns: %.2f\" % (episode+1, count, successes, episode+1, float(cumulative_reward)/(episode+1), float(cumulative_turns)/(episode+1)))\n",
    "    print(\"Success rate: %s / %s Avg reward: %.2f Avg turns: %.2f\" % (successes, count, float(cumulative_reward)/count, float(cumulative_turns)/count))\n",
    "    status['successes'] += successes\n",
    "    status['count'] += count\n",
    "    \n",
    "    if agt == 9 and params['trained_model_path'] == None:\n",
    "        save_model(params['write_model_dir'], agt, float(successes)/count, best_model['model'], best_res['epoch'], count)\n",
    "        save_performance_records(params['write_model_dir'], agt, performance_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warm_start starting ...\n",
      "warm_start simulation episode 0: Fail\n",
      "warm_start simulation episode 1: Fail\n",
      "warm_start simulation episode 2: Fail\n",
      "warm_start simulation episode 3: Fail\n",
      "warm_start simulation episode 4: Fail\n",
      "warm_start simulation episode 5: Success\n",
      "warm_start simulation episode 6: Fail\n",
      "warm_start simulation episode 7: Fail\n",
      "warm_start simulation episode 8: Success\n",
      "warm_start simulation episode 9: Success\n",
      "warm_start simulation episode 10: Fail\n",
      "warm_start simulation episode 11: Fail\n",
      "warm_start simulation episode 12: Fail\n",
      "warm_start simulation episode 13: Fail\n",
      "warm_start simulation episode 14: Fail\n",
      "warm_start simulation episode 15: Success\n",
      "warm_start simulation episode 16: Fail\n",
      "warm_start simulation episode 17: Fail\n",
      "warm_start simulation episode 18: Fail\n",
      "warm_start simulation episode 19: Success\n",
      "warm_start simulation episode 20: Fail\n",
      "warm_start simulation episode 21: Fail\n",
      "warm_start simulation episode 22: Fail\n",
      "warm_start simulation episode 23: Success\n",
      "warm_start simulation episode 24: Fail\n",
      "warm_start simulation episode 25: Fail\n",
      "warm_start simulation episode 26: Fail\n",
      "warm_start simulation episode 27: Fail\n",
      "warm_start simulation episode 28: Fail\n",
      "warm_start simulation episode 29: Fail\n",
      "warm_start simulation episode 30: Success\n",
      "warm_start simulation episode 31: Success\n",
      "warm_start simulation episode 32: Success\n",
      "warm_start simulation episode 33: Fail\n",
      "warm_start simulation episode 34: Success\n",
      "warm_start simulation episode 35: Success\n",
      "warm_start simulation episode 36: Fail\n",
      "warm_start simulation episode 37: Fail\n",
      "warm_start simulation episode 38: Fail\n",
      "warm_start simulation episode 39: Success\n",
      "warm_start simulation episode 40: Fail\n",
      "warm_start simulation episode 41: Fail\n",
      "warm_start simulation episode 42: Success\n",
      "warm_start simulation episode 43: Fail\n",
      "warm_start simulation episode 44: Fail\n",
      "warm_start simulation episode 45: Success\n",
      "warm_start simulation episode 46: Fail\n",
      "warm_start simulation episode 47: Fail\n",
      "warm_start simulation episode 48: Fail\n",
      "warm_start simulation episode 49: Success\n",
      "warm_start simulation episode 50: Fail\n",
      "warm_start simulation episode 51: Success\n",
      "warm_start simulation episode 52: Fail\n",
      "warm_start simulation episode 53: Success\n",
      "warm_start simulation episode 54: Success\n",
      "warm_start simulation episode 55: Success\n",
      "warm_start simulation episode 56: Fail\n",
      "warm_start simulation episode 57: Success\n",
      "warm_start simulation episode 58: Fail\n",
      "warm_start simulation episode 59: Fail\n",
      "warm_start simulation episode 60: Success\n",
      "warm_start simulation episode 61: Fail\n",
      "warm_start simulation episode 62: Fail\n",
      "warm_start simulation episode 63: Success\n",
      "warm_start simulation episode 64: Fail\n",
      "warm_start simulation episode 65: Fail\n",
      "warm_start simulation episode 66: Fail\n",
      "warm_start simulation episode 67: Fail\n",
      "warm_start simulation episode 68: Success\n",
      "warm_start simulation episode 69: Success\n",
      "warm_start simulation episode 70: Fail\n",
      "warm_start simulation episode 71: Fail\n",
      "warm_start simulation episode 72: Fail\n",
      "warm_start simulation episode 73: Fail\n",
      "warm_start simulation episode 74: Fail\n",
      "warm_start simulation episode 75: Fail\n",
      "warm_start simulation episode 76: Success\n",
      "warm_start simulation episode 77: Fail\n",
      "warm_start simulation episode 78: Fail\n",
      "warm_start simulation episode 79: Fail\n",
      "warm_start simulation episode 80: Fail\n",
      "warm_start simulation episode 81: Fail\n",
      "warm_start simulation episode 82: Fail\n",
      "warm_start simulation episode 83: Fail\n",
      "warm_start simulation episode 84: Fail\n",
      "warm_start simulation episode 85: Fail\n",
      "warm_start simulation episode 86: Success\n",
      "warm_start simulation episode 87: Fail\n",
      "warm_start simulation episode 88: Fail\n",
      "warm_start simulation episode 89: Fail\n",
      "warm_start simulation episode 90: Fail\n",
      "warm_start simulation episode 91: Fail\n",
      "warm_start simulation episode 92: Fail\n",
      "warm_start simulation episode 93: Fail\n",
      "warm_start simulation episode 94: Fail\n",
      "warm_start simulation episode 95: Fail\n",
      "warm_start simulation episode 96: Success\n",
      "warm_start simulation episode 97: Success\n",
      "warm_start simulation episode 98: Fail\n",
      "warm_start simulation episode 99: Fail\n",
      "warm_start simulation episode 100: Fail\n",
      "warm_start simulation episode 101: Fail\n",
      "warm_start simulation episode 102: Fail\n",
      "warm_start simulation episode 103: Fail\n",
      "warm_start simulation episode 104: Fail\n",
      "warm_start simulation episode 105: Fail\n",
      "warm_start simulation episode 106: Fail\n",
      "warm_start simulation episode 107: Success\n",
      "warm_start simulation episode 108: Success\n",
      "warm_start simulation episode 109: Fail\n",
      "warm_start simulation episode 110: Success\n",
      "warm_start simulation episode 111: Fail\n",
      "warm_start simulation episode 112: Fail\n",
      "warm_start simulation episode 113: Fail\n",
      "warm_start simulation episode 114: Fail\n",
      "warm_start simulation episode 115: Success\n",
      "warm_start simulation episode 116: Fail\n",
      "warm_start simulation episode 117: Fail\n",
      "warm_start simulation episode 118: Fail\n",
      "warm_start simulation episode 119: Fail\n",
      "Warm_Start 120 epochs, success rate 0.266666666667, ave reward -15.0, ave turns 16.0\n",
      "Current experience replay buffer size 960\n",
      "warm_start finished, start RL training ...\n",
      "Episode: 0\n",
      "Failed Dialog!\n",
      "simulation episode 0: Fail\n",
      "simulation episode 1: Fail\n",
      "simulation episode 2: Fail\n",
      "simulation episode 3: Fail\n",
      "simulation episode 4: Fail\n",
      "simulation episode 5: Fail\n",
      "simulation episode 6: Fail\n",
      "simulation episode 7: Fail\n",
      "simulation episode 8: Fail\n",
      "simulation episode 9: Fail\n",
      "simulation episode 10: Fail\n",
      "simulation episode 11: Fail\n",
      "simulation episode 12: Fail\n",
      "simulation episode 13: Fail\n",
      "simulation episode 14: Fail\n",
      "simulation episode 15: Fail\n",
      "simulation episode 16: Fail\n",
      "simulation episode 17: Fail\n",
      "simulation episode 18: Fail\n",
      "simulation episode 19: Fail\n",
      "simulation episode 20: Fail\n",
      "simulation episode 21: Fail\n",
      "simulation episode 22: Fail\n",
      "simulation episode 23: Fail\n",
      "simulation episode 24: Fail\n",
      "simulation episode 25: Fail\n",
      "simulation episode 26: Fail\n",
      "simulation episode 27: Fail\n",
      "simulation episode 28: Fail\n",
      "simulation episode 29: Fail\n",
      "simulation episode 30: Fail\n",
      "simulation episode 31: Fail\n",
      "simulation episode 32: Fail\n",
      "simulation episode 33: Fail\n",
      "simulation episode 34: Fail\n",
      "simulation episode 35: Fail\n",
      "simulation episode 36: Fail\n",
      "simulation episode 37: Fail\n",
      "simulation episode 38: Fail\n",
      "simulation episode 39: Fail\n",
      "simulation episode 40: Fail\n",
      "simulation episode 41: Fail\n",
      "simulation episode 42: Fail\n",
      "simulation episode 43: Fail\n",
      "simulation episode 44: Fail\n",
      "simulation episode 45: Fail\n",
      "simulation episode 46: Fail\n",
      "simulation episode 47: Fail\n",
      "simulation episode 48: Fail\n",
      "simulation episode 49: Fail\n",
      "simulation episode 50: Fail\n",
      "simulation episode 51: Fail\n",
      "simulation episode 52: Fail\n",
      "simulation episode 53: Fail\n",
      "simulation episode 54: Fail\n",
      "simulation episode 55: Fail\n",
      "simulation episode 56: Fail\n",
      "simulation episode 57: Fail\n",
      "simulation episode 58: Fail\n",
      "simulation episode 59: Fail\n",
      "simulation episode 60: Fail\n",
      "simulation episode 61: Fail\n",
      "simulation episode 62: Fail\n",
      "simulation episode 63: Fail\n",
      "simulation episode 64: Fail\n",
      "simulation episode 65: Fail\n",
      "simulation episode 66: Fail\n",
      "simulation episode 67: Fail\n",
      "simulation episode 68: Fail\n",
      "simulation episode 69: Fail\n",
      "simulation episode 70: Fail\n",
      "simulation episode 71: Fail\n",
      "simulation episode 72: Fail\n",
      "simulation episode 73: Fail\n",
      "simulation episode 74: Fail\n",
      "simulation episode 75: Fail\n",
      "simulation episode 76: Fail\n",
      "simulation episode 77: Fail\n",
      "simulation episode 78: Fail\n",
      "simulation episode 79: Fail\n",
      "simulation episode 80: Fail\n",
      "simulation episode 81: Fail\n",
      "simulation episode 82: Fail\n",
      "simulation episode 83: Fail\n",
      "simulation episode 84: Fail\n",
      "simulation episode 85: Fail\n",
      "simulation episode 86: Fail\n",
      "simulation episode 87: Fail\n",
      "simulation episode 88: Fail\n",
      "simulation episode 89: Fail\n",
      "simulation episode 90: Fail\n",
      "simulation episode 91: Fail\n",
      "simulation episode 92: Fail\n",
      "simulation episode 93: Fail\n",
      "simulation episode 94: Fail\n",
      "simulation episode 95: Fail\n",
      "simulation episode 96: Fail\n",
      "simulation episode 97: Fail\n",
      "simulation episode 98: Fail\n",
      "simulation episode 99: Fail\n",
      "simulation success rate 0.0, ave reward -58.8, ave turns 39.6\n",
      "cur bellman err 8.8961, experience replay pool 2940\n",
      "Simulation success rate 0.0, Ave reward -58.8, Ave turns 39.6, Best success rate 0\n",
      "saved model in ./agt_9_0_0_0.00000.p\n",
      "saved model in ./agt_9_performance_records.json\n",
      "Progress: 1 / 500, Success rate: 0 / 1 Avg reward: -60.00 Avg turns: 42.00\n",
      "Episode: 1\n",
      "Failed Dialog!\n",
      "simulation episode 0: Fail\n",
      "simulation episode 1: Fail\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation episode 2: Fail\n",
      "simulation episode 3: Fail\n",
      "simulation episode 4: Fail\n",
      "simulation episode 5: Fail\n",
      "simulation episode 6: Fail\n",
      "simulation episode 7: Fail\n",
      "simulation episode 8: Fail\n",
      "simulation episode 9: Fail\n",
      "simulation episode 10: Fail\n",
      "simulation episode 11: Fail\n",
      "simulation episode 12: Fail\n",
      "simulation episode 13: Fail\n",
      "simulation episode 14: Fail\n",
      "simulation episode 15: Fail\n",
      "simulation episode 16: Fail\n",
      "simulation episode 17: Fail\n",
      "simulation episode 18: Fail\n",
      "simulation episode 19: Fail\n",
      "simulation episode 20: Fail\n",
      "simulation episode 21: Fail\n",
      "simulation episode 22: Fail\n",
      "simulation episode 23: Fail\n",
      "simulation episode 24: Fail\n",
      "simulation episode 25: Fail\n",
      "simulation episode 26: Fail\n",
      "simulation episode 27: Fail\n",
      "simulation episode 28: Fail\n",
      "simulation episode 29: Fail\n",
      "simulation episode 30: Fail\n",
      "simulation episode 31: Fail\n",
      "simulation episode 32: Fail\n",
      "simulation episode 33: Fail\n",
      "simulation episode 34: Fail\n",
      "simulation episode 35: Fail\n",
      "simulation episode 36: Fail\n",
      "simulation episode 37: Fail\n",
      "simulation episode 38: Fail\n",
      "simulation episode 39: Fail\n",
      "simulation episode 40: Fail\n",
      "simulation episode 41: Fail\n",
      "simulation episode 42: Fail\n",
      "simulation episode 43: Fail\n",
      "simulation episode 44: Fail\n",
      "simulation episode 45: Fail\n",
      "simulation episode 46: Fail\n",
      "simulation episode 47: Fail\n",
      "simulation episode 48: Fail\n",
      "simulation episode 49: Fail\n",
      "simulation episode 50: Fail\n",
      "simulation episode 51: Fail\n",
      "simulation episode 52: Fail\n",
      "simulation episode 53: Fail\n",
      "simulation episode 54: Fail\n",
      "simulation episode 55: Fail\n",
      "simulation episode 56: Fail\n",
      "simulation episode 57: Fail\n",
      "simulation episode 58: Fail\n",
      "simulation episode 59: Fail\n",
      "simulation episode 60: Fail\n",
      "simulation episode 61: Fail\n",
      "simulation episode 62: Fail\n",
      "simulation episode 63: Fail\n",
      "simulation episode 64: Fail\n",
      "simulation episode 65: Fail\n",
      "simulation episode 66: Fail\n",
      "simulation episode 67: Fail\n",
      "simulation episode 68: Fail\n",
      "simulation episode 69: Fail\n",
      "simulation episode 70: Fail\n",
      "simulation episode 71: Fail\n",
      "simulation episode 72: Fail\n",
      "simulation episode 73: Fail\n",
      "simulation episode 74: Fail\n",
      "simulation episode 75: Fail\n",
      "simulation episode 76: Fail\n",
      "simulation episode 77: Fail\n",
      "simulation episode 78: Fail\n",
      "simulation episode 79: Fail\n",
      "simulation episode 80: Fail\n",
      "simulation episode 81: Fail\n",
      "simulation episode 82: Fail\n",
      "simulation episode 83: Fail\n",
      "simulation episode 84: Fail\n",
      "simulation episode 85: Fail\n",
      "simulation episode 86: Fail\n",
      "simulation episode 87: Fail\n",
      "simulation episode 88: Fail\n",
      "simulation episode 89: Fail\n",
      "simulation episode 90: Fail\n",
      "simulation episode 91: Fail\n",
      "simulation episode 92: Fail\n",
      "simulation episode 93: Fail\n",
      "simulation episode 94: Fail\n",
      "simulation episode 95: Fail\n",
      "simulation episode 96: Fail\n",
      "simulation episode 97: Fail\n",
      "simulation episode 98: Fail\n",
      "simulation episode 99: Fail\n",
      "simulation success rate 0.0, ave reward -49.58, ave turns 21.16\n",
      "cur bellman err 5.2085, experience replay pool 3998\n",
      "Simulation success rate 0.0, Ave reward -49.58, Ave turns 21.16, Best success rate 0\n",
      "Progress: 2 / 500, Success rate: 0 / 2 Avg reward: -50.00 Avg turns: 22.00\n",
      "Episode: 2\n",
      "Failed Dialog!\n",
      "simulation episode 0: Fail\n",
      "simulation episode 1: Fail\n",
      "simulation episode 2: Fail\n",
      "simulation episode 3: Fail\n",
      "simulation episode 4: Fail\n",
      "simulation episode 5: Fail\n",
      "simulation episode 6: Fail\n",
      "simulation episode 7: Fail\n",
      "simulation episode 8: Fail\n",
      "simulation episode 9: Fail\n",
      "simulation episode 10: Fail\n",
      "simulation episode 11: Fail\n",
      "simulation episode 12: Fail\n",
      "simulation episode 13: Fail\n",
      "simulation episode 14: Fail\n",
      "simulation episode 15: Fail\n",
      "simulation episode 16: Fail\n",
      "simulation episode 17: Fail\n",
      "simulation episode 18: Fail\n",
      "simulation episode 19: Fail\n",
      "simulation episode 20: Fail\n",
      "simulation episode 21: Fail\n",
      "simulation episode 22: Fail\n",
      "simulation episode 23: Fail\n",
      "simulation episode 24: Fail\n",
      "simulation episode 25: Fail\n",
      "simulation episode 26: Fail\n",
      "simulation episode 27: Fail\n",
      "simulation episode 28: Fail\n",
      "simulation episode 29: Fail\n",
      "simulation episode 30: Fail\n",
      "simulation episode 31: Fail\n",
      "simulation episode 32: Fail\n",
      "simulation episode 33: Fail\n",
      "simulation episode 34: Fail\n",
      "simulation episode 35: Fail\n",
      "simulation episode 36: Fail\n",
      "simulation episode 37: Fail\n",
      "simulation episode 38: Fail\n",
      "simulation episode 39: Fail\n",
      "simulation episode 40: Fail\n",
      "simulation episode 41: Fail\n",
      "simulation episode 42: Fail\n",
      "simulation episode 43: Fail\n",
      "simulation episode 44: Fail\n",
      "simulation episode 45: Fail\n",
      "simulation episode 46: Fail\n",
      "simulation episode 47: Fail\n",
      "simulation episode 48: Fail\n",
      "simulation episode 49: Fail\n",
      "simulation episode 50: Fail\n",
      "simulation episode 51: Fail\n",
      "simulation episode 52: Fail\n",
      "simulation episode 53: Fail\n",
      "simulation episode 54: Fail\n",
      "simulation episode 55: Fail\n",
      "simulation episode 56: Fail\n",
      "simulation episode 57: Fail\n",
      "simulation episode 58: Fail\n",
      "simulation episode 59: Fail\n",
      "simulation episode 60: Fail\n",
      "simulation episode 61: Fail\n",
      "simulation episode 62: Fail\n",
      "simulation episode 63: Fail\n",
      "simulation episode 64: Fail\n",
      "simulation episode 65: Fail\n",
      "simulation episode 66: Fail\n",
      "simulation episode 67: Fail\n",
      "simulation episode 68: Fail\n",
      "simulation episode 69: Fail\n",
      "simulation episode 70: Fail\n",
      "simulation episode 71: Fail\n",
      "simulation episode 72: Fail\n",
      "simulation episode 73: Fail\n",
      "simulation episode 74: Fail\n",
      "simulation episode 75: Fail\n",
      "simulation episode 76: Fail\n",
      "simulation episode 77: Fail\n",
      "simulation episode 78: Fail\n",
      "simulation episode 79: Fail\n",
      "simulation episode 80: Fail\n",
      "simulation episode 81: Fail\n",
      "simulation episode 82: Fail\n",
      "simulation episode 83: Fail\n",
      "simulation episode 84: Fail\n",
      "simulation episode 85: Fail\n",
      "simulation episode 86: Fail\n",
      "simulation episode 87: Fail\n",
      "simulation episode 88: Fail\n",
      "simulation episode 89: Fail\n",
      "simulation episode 90: Fail\n",
      "simulation episode 91: Fail\n",
      "simulation episode 92: Fail\n",
      "simulation episode 93: Fail\n",
      "simulation episode 94: Fail\n",
      "simulation episode 95: Fail\n",
      "simulation episode 96: Fail\n",
      "simulation episode 97: Fail\n",
      "simulation episode 98: Fail\n",
      "simulation episode 99: Fail\n",
      "simulation success rate 0.0, ave reward -59.87, ave turns 41.74\n",
      "cur bellman err 2.9151, experience replay pool 6085\n",
      "Simulation success rate 0.0, Ave reward -59.87, Ave turns 41.74, Best success rate 0\n",
      "Progress: 3 / 500, Success rate: 0 / 3 Avg reward: -53.33 Avg turns: 28.67\n",
      "Episode: 3\n",
      "Failed Dialog!\n",
      "simulation episode 0: Fail\n",
      "simulation episode 1: Fail\n",
      "simulation episode 2: Fail\n",
      "simulation episode 3: Fail\n",
      "simulation episode 4: Fail\n",
      "simulation episode 5: Fail\n",
      "simulation episode 6: Fail\n",
      "simulation episode 7: Fail\n",
      "simulation episode 8: Fail\n",
      "simulation episode 9: Fail\n",
      "simulation episode 10: Fail\n",
      "simulation episode 11: Fail\n",
      "simulation episode 12: Fail\n",
      "simulation episode 13: Fail\n",
      "simulation episode 14: Fail\n",
      "simulation episode 15: Fail\n",
      "simulation episode 16: Fail\n",
      "simulation episode 17: Fail\n",
      "simulation episode 18: Fail\n",
      "simulation episode 19: Fail\n",
      "simulation episode 20: Fail\n",
      "simulation episode 21: Fail\n",
      "simulation episode 22: Fail\n",
      "simulation episode 23: Fail\n",
      "simulation episode 24: Fail\n",
      "simulation episode 25: Fail\n",
      "simulation episode 26: Fail\n",
      "simulation episode 27: Fail\n",
      "simulation episode 28: Fail\n",
      "simulation episode 29: Fail\n",
      "simulation episode 30: Fail\n",
      "simulation episode 31: Fail\n",
      "simulation episode 32: Fail\n",
      "simulation episode 33: Fail\n",
      "simulation episode 34: Fail\n",
      "simulation episode 35: Fail\n",
      "simulation episode 36: Fail\n",
      "simulation episode 37: Fail\n",
      "simulation episode 38: Fail\n",
      "simulation episode 39: Fail\n",
      "simulation episode 40: Fail\n",
      "simulation episode 41: Fail\n",
      "simulation episode 42: Fail\n",
      "simulation episode 43: Fail\n",
      "simulation episode 44: Fail\n",
      "simulation episode 45: Fail\n",
      "simulation episode 46: Fail\n",
      "simulation episode 47: Fail\n",
      "simulation episode 48: Fail\n",
      "simulation episode 49: Fail\n",
      "simulation episode 50: Fail\n",
      "simulation episode 51: Fail\n",
      "simulation episode 52: Fail\n",
      "simulation episode 53: Fail\n",
      "simulation episode 54: Fail\n",
      "simulation episode 55: Fail\n",
      "simulation episode 56: Fail\n",
      "simulation episode 57: Fail\n",
      "simulation episode 58: Fail\n",
      "simulation episode 59: Fail\n",
      "simulation episode 60: Fail\n",
      "simulation episode 61: Fail\n",
      "simulation episode 62: Fail\n",
      "simulation episode 63: Fail\n",
      "simulation episode 64: Fail\n",
      "simulation episode 65: Fail\n",
      "simulation episode 66: Fail\n",
      "simulation episode 67: Fail\n",
      "simulation episode 68: Fail\n",
      "simulation episode 69: Fail\n",
      "simulation episode 70: Fail\n",
      "simulation episode 71: Fail\n",
      "simulation episode 72: Fail\n",
      "simulation episode 73: Fail\n",
      "simulation episode 74: Fail\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulation episode 75: Fail\n",
      "simulation episode 76: Fail\n",
      "simulation episode 77: Fail\n",
      "simulation episode 78: Fail\n",
      "simulation episode 79: Fail\n",
      "simulation episode 80: Fail\n",
      "simulation episode 81: Fail\n",
      "simulation episode 82: Fail\n",
      "simulation episode 83: Fail\n",
      "simulation episode 84: Fail\n",
      "simulation episode 85: Fail\n",
      "simulation episode 86: Fail\n",
      "simulation episode 87: Fail\n",
      "simulation episode 88: Fail\n",
      "simulation episode 89: Fail\n",
      "simulation episode 90: Fail\n",
      "simulation episode 91: Fail\n",
      "simulation episode 92: Fail\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-633fa5128ee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_episodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-7f956b886c79>\u001b[0m in \u001b[0;36mrun_episodes\u001b[0;34m(count, status)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0magt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m9\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trained_model_path'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0msimulation_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulation_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulation_epoch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mperformance_records\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'success_rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimulation_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'success_rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-7f956b886c79>\u001b[0m in \u001b[0;36msimulation_epoch\u001b[0;34m(simulation_epoch_size)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mepisode_over\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mepisode_over\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mepisode_over\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdialog_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_turn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mcumulative_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mepisode_over\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-adc90388bd23>\u001b[0m in \u001b[0;36mnext_turn\u001b[0;34m(self, record_training_data)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m########################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_tracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state_for_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_to_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m########################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-4c0d1326a08e>\u001b[0m in \u001b[0;36mstate_to_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_state_representation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mact_slot_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeasible_actions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'act_slot_response'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mact_slot_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'act_slot_value_response'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-4c0d1326a08e>\u001b[0m in \u001b[0;36mrun_policy\u001b[0;34m(self, representation)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrule_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrule_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-eae17506d24e>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, Xs, params, **kwargs)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;34m\"\"\" prediction \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mYs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfwdPass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m         \u001b[0mpred_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-eae17506d24e>\u001b[0m in \u001b[0;36mfwdPass\u001b[0;34m(self, Xs, params, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mWxh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Wxh'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mbxh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bxh'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mXsh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWxh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbxh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Wd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# size of hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_episodes(num_episodes, status)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
